<!-- build time:Sun Dec 03 2017 21:25:11 GMT+0800 (CST) --><!DOCTYPE html><html class="theme-next mist" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3"><link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222"><meta name="keywords" content="Hexo, NexT"><meta name="description" content="搜索引擎的定义与组成在大量的文档中搜索一系列单词，根据文档与这些单词的相关程度，对搜索结果进行排名。本章中我们将将学到如何搜索引起的数据处理与数据检索的方法：数据处理：抓取网页（crawl）、建立索引（index）数据检索：从多种角度度量不同文档与搜索关键词的相关程度，根据相关程度对文档进行排序。建立搜索引擎的步骤数据"><meta property="og:type" content="article"><meta property="og:title" content="搜索与排名"><meta property="og:url" content="laiqun.github.io/2017/12/02/SearchAndRanking/index.html"><meta property="og:site_name" content="广阔天地，大有作为"><meta property="og:description" content="搜索引擎的定义与组成在大量的文档中搜索一系列单词，根据文档与这些单词的相关程度，对搜索结果进行排名。本章中我们将将学到如何搜索引起的数据处理与数据检索的方法：数据处理：抓取网页（crawl）、建立索引（index）数据检索：从多种角度度量不同文档与搜索关键词的相关程度，根据相关程度对文档进行排序。建立搜索引擎的步骤数据处理第一步： 我们首先要有数据来供搜索引擎来检索才行，即我们要有一种收集文档的方"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="/2017/12/02/SearchAndRanking/ER.png"><meta property="og:image" content="/2017/12/02/SearchAndRanking/ER2.png"><meta property="og:image" content="/2017/12/02/SearchAndRanking/ER_LINK.png"><meta property="og:image" content="/2017/12/02/SearchAndRanking/sch.PNG"><meta property="og:image" content="/2017/12/02/SearchAndRanking/sch2.png"><meta property="og:updated_time" content="2017-12-03T13:20:21.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="搜索与排名"><meta name="twitter:description" content="搜索引擎的定义与组成在大量的文档中搜索一系列单词，根据文档与这些单词的相关程度，对搜索结果进行排名。本章中我们将将学到如何搜索引起的数据处理与数据检索的方法：数据处理：抓取网页（crawl）、建立索引（index）数据检索：从多种角度度量不同文档与搜索关键词的相关程度，根据相关程度对文档进行排序。建立搜索引擎的步骤数据处理第一步： 我们首先要有数据来供搜索引擎来检索才行，即我们要有一种收集文档的方"><meta name="twitter:image" content="/2017/12/02/SearchAndRanking/ER.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",version:"5.1.3",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!0},fancybox:!0,tabs:!0,motion:{enable:!1,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="laiqun.github.io/2017/12/02/SearchAndRanking/"><title>搜索与排名 | 广阔天地，大有作为</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">广阔天地，大有作为</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">你看到我的筋斗云了嘛？</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="laiqun.github.io/2017/12/02/SearchAndRanking/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="倔强的土豆"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="广阔天地，大有作为"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">搜索与排名</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-02T16:27:03+08:00">2017-12-02 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/12/02/SearchAndRanking/#comments" itemprop="discussionUrl"><span class="post-comments-count gitment-comments-count" data-xid="/2017/12/02/SearchAndRanking/" itemprop="commentsCount"></span></a></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="搜索引擎的定义与组成"><a href="#搜索引擎的定义与组成" class="headerlink" title="搜索引擎的定义与组成"></a>搜索引擎的定义与组成</h1><p>在大量的文档中<strong>搜索</strong>一系列单词，根据文档与这些单词的相关程度，对搜索结果进行排名。<br>本章中我们将将学到如何搜索引起的数据处理与数据检索的方法：<br>数据处理：<strong>抓取网页</strong>（crawl）、<strong>建立索引</strong>（index）<br>数据检索：从多种角度<strong>度量</strong>不同文档与搜索关键词的<strong>相关程度</strong>，根据相关程度对文档进行排序。</p><h1 id="建立搜索引擎的步骤"><a href="#建立搜索引擎的步骤" class="headerlink" title="建立搜索引擎的步骤"></a>建立搜索引擎的步骤</h1><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p>第一步： 我们首先要有数据来供搜索引擎来检索才行，即我们要有一种收集文档的方法，也叫做网页抓取。我们先从抓取一组网页开始，然后根据这些网页内的链接逐渐抓取这些链接中的页面。<br>第二步： 为收集到的文档建立索引，因为我们要根据输入的关键字来检索文档，故这里我们将文档拆成一个个单词，创建一个单词与文档的表格。</p><table><thead><tr><th>单词</th><th>文档名</th></tr></thead><tbody><tr><td>单词1</td><td>文档1</td></tr><tr><td>单词1</td><td>文档2</td></tr><tr><td>单词2</td><td>文档2</td></tr></tbody></table><p>以上数据的含义为单词1在文档1和文档2中出现过。单词2在文档2中出现过。<br>但这里我们会发现好像漏掉了一些信息，单词的位置是对搜索结果进行排序的重要依据，比如有两篇文档，一篇文档在标题的时候就涵盖了我们要搜索的关键字，而另一篇只在末尾提到了我们要搜索的关键字，这时候，标题中包含关键字的文档往往就是我们要找的，故<strong>单词在文档中的位置</strong>是对搜索结果进行排序的一个重要指标。</p><p>我们改进一下表格的结构，添加上单词在文档中的出现的位置。值得注意的是，一个单词可能在一篇文档中被提到多次。</p><table><thead><tr><th>单词</th><th>文档名</th><th>文档位置</th></tr></thead><tbody><tr><td>单词1</td><td>文档1</td><td>第1次出现的位置</td></tr><tr><td>单词1</td><td>文档1</td><td>第2次出现的位置</td></tr><tr><td>单词1</td><td>文档1</td><td>第n次出现的位置</td></tr><tr><td>单词1</td><td>文档2</td><td>第1次出现的位置</td></tr><tr><td>单词1</td><td>文档2</td><td>第n次出现的位置</td></tr><tr><td>单词2</td><td>文档2</td><td>第1次出现的位置</td></tr></tbody></table><p>根据数据库的表格的设计原则，当一个表中的数据出现大量重复的时候，这时候往往需要拆分表格。</p><p>我们将上述表格修改为三个表格，单词表、文档名表和‘单词所处文档名与在文档中的位置描述表’。</p><img src="/2017/12/02/SearchAndRanking/ER.png" title="ER图"><p><em>上图为ER图，方形表示实体，圆圈表示属性，一个实体有多个属性。棱形表示联系，连线上的数量表示两个实体之间的关系。</em></p><p>图中有两对关系。</p><ol><li>关系1： 单词表与‘单词所处文档名与在文档中的位置描述表’两个表之间的关系是1：N，因为一个单词可以在一篇文档的多个位置出现。有了这两个表格，这样单词就不会重复书写多次啦。</li><li>关系2： 文档列表与‘单词所处文档名与在文档中的位置描述表’两个表之间的关系为1：N，因为一个文档名可能在‘单词所处文档名与在文档中的位置描述表’中被引用很多次。‘单词所处文档名与在文档中的位置描述表’中引用了文档名，如果不拆分，那么同一个文档名会被写多次。如果将文档名单独划分成一个表，引用一个文档的话只要使用文档id就可以啦，避免反复拼写完整的文档名。</li></ol><p>到目前位置，我们已经可以根据单词来检索到哪些文档中含有这些单词、以及他们在文档中的位置。</p><p>不过现在只能一次处理一个单词，而且只能以文档当初被加载的顺序返回文档。</p><p>文档的顺序还需要优化，我们需要计算搜索关键字和文档之间的相关程度，相关程度越大，就应该越靠前显示。这些将在<strong>数据检索</strong>中完成。</p><h2 id="数据检索"><a href="#数据检索" class="headerlink" title="数据检索"></a>数据检索</h2><p>第一步：数据检索即数据查询，我们要根据输入的一系列单词，返回一个经过排序的文档列表。对搜索结果进行排序，我们需要几个度量指标来量化它们与搜索关键词的匹配程度。我们将学习到不同的量化指标，比如单词频率、单词出现的位置、单词位置之间的距离（如果用户输入了多个关键词的话）、其他页面对本页面的引用次数（google的pagerank算法）等。<br>HTML页面中的链接用a标签表示，为了能够表述页面引用情况，我们要对表格关系再做修改，将链接信息单独提取出来。</p><img src="/2017/12/02/SearchAndRanking/ER2.png" title="增加衔接描述"><p>上图表示一个链接包含三个属性：衔接处的描述单词、链接来自、衔接去向。衔接处的描述单词我们可以在单词表中找到。链接来自与衔接去向可在文档列表中找到对应。一个链接可能包含多个单词描述。比如<br></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"www.google.com"</span>&gt;</span></span><br><span class="line">  google good search</span><br><span class="line"><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>上述代码中‘google’、‘good’、‘search’都指向链接到google的a标签,制作成表格如下：</p><table><thead><tr><th>单词</th><th>去哪</th></tr></thead><tbody><tr><td>google</td><td>www.google.com</td></tr><tr><td>good</td><td>www.google.com</td></tr><tr><td>search</td><td>www.google.com</td></tr></tbody></table><p>我们注意到‘去哪’所处的列有很大的重复性，‘www.google.com’被重复写了三次，这意味着我们可以拆分表格来减少冗余。<br><img src="/2017/12/02/SearchAndRanking/ER_LINK.png" title="拆分链接实体表"><br>经过上述拆分之后，我们写‘www.google.com’的时候，只需要引用它的id即可，避免了多次重复书写。</p><p>第二步：我们把搜索结果呈递给用户之后，用户会点击自己想要的链接，我们需要<strong>学习</strong>用户的点击信息来对搜索结果中文档的顺序进行调整。我们会依靠用户的点击信息来建立<strong>神经网络</strong>来优化搜索结果的排名，神经网络会学习到人们过去的点击情况。</p><h1 id="抓取数据"><a href="#抓取数据" class="headerlink" title="抓取数据"></a>抓取数据</h1><p>假设我们硬盘中没有成堆的HTML文档在等待索引，那我们就写一个简单的爬虫程序来下载HTML文档，它接收一组等待下载的网页URL，然后根据这些网站中的链接来找到其他页面，这个过程叫<strong>蛛行</strong>（Spidering）。</p><h2 id="使用urllib来下载网页"><a href="#使用urllib来下载网页" class="headerlink" title="使用urllib来下载网页"></a>使用urllib来下载网页</h2><p>urllib是一个python库，作用是方便网页下载，我们只需要传入网站的URL。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line">c=urllib.request.urlopen(<span class="string">'http://test.com'</span>)</span><br><span class="line">contents = c.read()</span><br><span class="line">print(contents[<span class="number">0</span>:<span class="number">50</span>])</span><br></pre></td></tr></table></figure><p></p><h2 id="书写爬虫"><a href="#书写爬虫" class="headerlink" title="书写爬虫"></a>书写爬虫</h2><p>这个程序使用BeautifulSoup，它能为网页建立结构化的表现形式，并且对书写不规范的页面容错性较好。<br>使用urllib和BeautifulSoup，传入一组初始的URL列表，根据URL得到网页之后，可以根据网页中的链接信息找到其他网页。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> urlparse <span class="keyword">import</span> urljoin</span><br><span class="line"><span class="comment"># 构建一个单词列表，这些单词将被忽略</span></span><br><span class="line">ingorewords=([<span class="string">'the'</span>,<span class="string">'of'</span>,<span class="string">'to'</span>,<span class="string">'and'</span>,<span class="string">'a'</span>,<span class="string">'in'</span>,<span class="string">'is'</span>,<span class="string">'it'</span>])</span><br></pre></td></tr></table></figure><p></p><p>现在，我们可以书写爬虫代码了。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">crawler</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">crawl</span><span class="params">(self,pages,depth=<span class="number">2</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(depth):</span><br><span class="line">      newpages = set()</span><br><span class="line">      <span class="keyword">for</span> page <span class="keyword">in</span> pages:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">          c = urllib.request.urlopen(page)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">          print(<span class="string">"Could not open %s"</span>% page)</span><br><span class="line">          <span class="keyword">continue</span></span><br><span class="line">        soup = BeautifulSoup(c.read()) <span class="comment"># 调用c.read()下载网页</span></span><br><span class="line">        self.addtoindex(page,soup) <span class="comment"># 下载后建立索引，这是下一小节中的函数,将在下一小节讲解</span></span><br><span class="line">        <span class="comment"># 下面我们来处理这个页面中的链接</span></span><br><span class="line">        links = soup(<span class="string">'a'</span>)</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">          <span class="keyword">if</span> (<span class="string">'href'</span> <span class="keyword">in</span> dict(link.attrs)): <span class="comment">#&lt;a href=""&gt; </span></span><br><span class="line">            url = urljoin(page,link[<span class="string">'href'</span>])</span><br><span class="line">          <span class="comment">#如果有单引号，说明该url和当前的URL的根域名不是同一个域名，如 baidu.com 与jd.com</span></span><br><span class="line">            <span class="keyword">if</span> url.find(<span class="string">"'"</span>)!=<span class="number">-1</span>: </span><br><span class="line">              <span class="keyword">continue</span></span><br><span class="line">            url = url.split(<span class="string">'#'</span>)[<span class="number">0</span>] <span class="comment"># 去掉页内定位部分，url中#后为锚点</span></span><br><span class="line">            <span class="comment"># 如果是一个网页链接，并且没有被索引过</span></span><br><span class="line">            <span class="comment"># isindexed判断是否已经是否已经索引过，避免重复索引</span></span><br><span class="line">            <span class="keyword">if</span> url[<span class="number">0</span>:<span class="number">4</span>] ==<span class="string">'http'</span> <span class="keyword">and</span> <span class="keyword">not</span> self.isindexed(url): </span><br><span class="line">              newpages.add(url)</span><br><span class="line">            linkText = self.gettextonly(link) <span class="comment">#获取a标签的描述文字,这将在下一小节中讲解</span></span><br><span class="line">      <span class="comment"># page代表当前url，url代表去向，即’去哪‘，linkText为链接上的文本</span></span><br><span class="line">            self.addlinkref(page,url,linkText)  <span class="comment">#这是建立索引部分，下一小节讲解</span></span><br><span class="line">        self.dbcommit()<span class="comment"># 下一小节讲解</span></span><br><span class="line">      <span class="comment"># 输入的URL搜索完后，要根据页面中的链接来找到其他页面  </span></span><br><span class="line">      pages = newpages</span><br></pre></td></tr></table></figure><p></p><p>该函数循环遍历网页列表，并针对每个网页调用addtoindex函数。addtoindex是建立索引部分，故我们这里暂时只把url打印出来<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addtoindex</span><span class="params">(self,url,soup)</span>:</span></span><br><span class="line">  print(<span class="string">'Indexing %s'</span> % url)</span><br></pre></td></tr></table></figure><p></p><p>随后，该函数利用BeautifulSoup取到网页中的所有链接，并将这些链接加入到一个名为newpages的集合中，一组url处理完毕后，我们将得到的newpages集合复制给pages，然后开启新的循环来处理这些url。</p><p>如果你学过二叉树遍历，那么很容易就知道上述过程其实就是广度优先搜索，我们也可以将其改成递归的深度优先搜索的形式，但递归层级较深时容易导致栈溢出。</p><p>我们来测试一下上述函数:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pageslist=[<span class="string">'http://kiwitobes.com/wiki/Perl.html'</span>]</span><br><span class="line">c = crawler(<span class="string">''</span>)</span><br><span class="line">crawl(pagelist)</span><br></pre></td></tr></table></figure><p></p><h1 id="建立索引"><a href="#建立索引" class="headerlink" title="建立索引"></a>建立索引</h1><p>建立索引的过程如前文所述，我们要建立一个数据表，其中包含了不同的单词、这些单词所在的文档和单词在文档中出现的位置。</p><p>在本例中，我们真正的文本内容进行考察，忽略非文本元素（如标点符号）。将文本内容拆解为单词，并给单词建立索引。</p><p>我们将使用sqlite来建立数据库，python3的标准库中已经有这个库了。</p><p>我们修改crawler类，增加数据库操作：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">crawler</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,dbname)</span>:</span></span><br><span class="line">    self.con = sqlite3.connect(dbname)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__del__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.con.close()</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">dbcommit</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.con.commit()<span class="comment"># 保存修改</span></span><br></pre></td></tr></table></figure><p></p><h2 id="设计数据库中的数据表"><a href="#设计数据库中的数据表" class="headerlink" title="设计数据库中的数据表"></a>设计数据库中的数据表</h2><p>根据前面的数据库的ER图，我们来设计数据库的表格。</p><table><thead><tr><th>表格名</th><th>表格描述</th></tr></thead><tbody><tr><td>urllist</td><td>保存已经索引过的URL列表</td></tr><tr><td>wordlist</td><td>单词列表</td></tr><tr><td>wordlocation</td><td>单词所在文档与在文档中所处的位置的列表</td></tr><tr><td>link</td><td>链接表，保存两个URL ID，指明从一个文档到另一个文档的链接关系</td></tr><tr><td>linkwords</td><td>哪些单词与链接有关</td></tr></tbody></table><img src="/2017/12/02/SearchAndRanking/sch.PNG" title="数据表设计图"><p>我们在这个图上更新一下对应关系：<br><img src="/2017/12/02/SearchAndRanking/sch2.png" title="数据表设计图"><br><em>上图链接表明，单词列表与’单词所处位置表‘的关系为1：N，即一个单词可以在文档中的多个位置出现。一个链接上可以有多个单词，所以link和linkwords的关系为1:N。文档名会被’单词所处位置表‘引用多次，所以关系为1：N。链接单词表中的单词在单词表中都能找到唯一的对应关系，故关系为1：1。链接表的的来自和去向分别对应url中的文档，故关系都是1：1。</em></p><p>所有的sqlite的表默认都有一个名为rowid的字段，故没有必要显示指定ID字段。</p><p>下面我们来写程序建立数据表：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">crawler</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createindextables</span><span class="params">(self)</span>:</span> </span><br><span class="line">    self.con.execute(<span class="string">'create table urllist(url)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create table wordlist(word)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create table wordlocation(urlid,wordid,location)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create table link(fromid integer,toid integer)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create table linkwords(wordid,linkid)'</span>)</span><br><span class="line">    <span class="comment"># 建立索引，加快搜索速度，该操作很重要，因为数据集会很大</span></span><br><span class="line">    self.con.execute(<span class="string">'create index wordidx on wordlist(word)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create index urlidx on urllist(url)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create index wordurlidx on wordlocation(wordid)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create index urltoidx on link(toid)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create index urlfromidx on link(fromid)'</span>)</span><br><span class="line">    self.dbcommit()</span><br></pre></td></tr></table></figure><p></p><p>测试代码，创建一个名为searchindex.db的数据库文件。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c=crawler(<span class="string">'searchindex.db'</span>)</span><br><span class="line">c.createindextables()</span><br></pre></td></tr></table></figure><p></p><p>我们会在查询阶段再加入一张表，它根据指向该文档的其他文档(外部回指链接-inbound link)的计数情况来作为度量。</p><h2 id="在网页中查找单词"><a href="#在网页中查找单词" class="headerlink" title="在网页中查找单词"></a>在网页中查找单词</h2><h2 id="加入索引"><a href="#加入索引" class="headerlink" title="加入索引"></a>加入索引</h2><h1 id="采用度量标准来优化文档排名"><a href="#采用度量标准来优化文档排名" class="headerlink" title="采用度量标准来优化文档排名"></a>采用度量标准来优化文档排名</h1><h1 id="利用神经网络学习数据之间的关联"><a href="#利用神经网络学习数据之间的关联" class="headerlink" title="利用神经网络学习数据之间的关联"></a>利用神经网络学习数据之间的关联</h1></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>如果您觉得读完本文有收获，不妨小额赞助我一下，让我有动力继续写出高质量的教程！</div><button id="rewardButton" disable="enable"><span>打赏</span></button><div id="QR" style="display:block"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/smacker.jpg" alt="倔强的土豆 微信支付"><p>微信支付</p></div></div></div></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/11/12/cluster/" rel="next" title="发现群组"><i class="fa fa-chevron-left"></i> 发现群组</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></div></article><div class="post-spread"></div></div></div><div class="comments" id="comments"><div id="gitment-container"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div id="sidebar-dimmer"></div><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">倔强的土豆</p><p class="site-description motion-element" itemprop="description">分享机器学习、深度学习的点滴</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">5</span> <span class="site-state-item-name">日志</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/laiqun" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:laiqun@msn.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#搜索引擎的定义与组成"><span class="nav-number">1.</span> <span class="nav-text">搜索引擎的定义与组成</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#建立搜索引擎的步骤"><span class="nav-number">2.</span> <span class="nav-text">建立搜索引擎的步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据处理"><span class="nav-number">2.1.</span> <span class="nav-text">数据处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据检索"><span class="nav-number">2.2.</span> <span class="nav-text">数据检索</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#抓取数据"><span class="nav-number">3.</span> <span class="nav-text">抓取数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#使用urllib来下载网页"><span class="nav-number">3.1.</span> <span class="nav-text">使用urllib来下载网页</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#书写爬虫"><span class="nav-number">3.2.</span> <span class="nav-text">书写爬虫</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#建立索引"><span class="nav-number">4.</span> <span class="nav-text">建立索引</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#设计数据库中的数据表"><span class="nav-number">4.1.</span> <span class="nav-text">设计数据库中的数据表</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#在网页中查找单词"><span class="nav-number">4.2.</span> <span class="nav-text">在网页中查找单词</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#加入索引"><span class="nav-number">4.3.</span> <span class="nav-text">加入索引</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#采用度量标准来优化文档排名"><span class="nav-number">5.</span> <span class="nav-text">采用度量标准来优化文档排名</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#利用神经网络学习数据之间的关联"><span class="nav-number">6.</span> <span class="nav-text">利用神经网络学习数据之间的关联</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2017</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">倔强的土豆</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script><link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css"><script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script><script type="text/javascript">function renderGitment(){var a=new Gitmint({id:window.location.pathname,owner:"laiqun",repo:"laiqun.github.io",lang:navigator.language||navigator.systemLanguage||navigator.userLanguage,oauth:{client_secret:"55aaeb736714431ea52109dd66461b1644ca6177",client_id:"c90dfa80285ea91b9120"}});a.render("gitment-container")}renderGitment()</script></body></html><!-- rebuild by neat -->