<!-- build time:Wed Dec 13 2017 00:47:31 GMT+0800 (CST) --><!DOCTYPE html><html class="theme-next mist" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3"><link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222"><meta name="keywords" content="Hexo, NexT"><meta name="description" content="搜索引擎的定义与组成在大量的文档中搜索一系列单词，根据文档与这些单词的相关程度，对搜索结果进行排名。本章中我们将将学到如何搜索引起的数据处理与数据检索的方法：数据处理：抓取网页（crawl）、建立索引（index）数据检索：从多种角度度量不同文档与搜索关键词的相关程度，根据相关程度对文档进行排序。数据处理过程目的是获取"><meta property="og:type" content="article"><meta property="og:title" content="搜索与排名"><meta property="og:url" content="laiqun.github.io/2017/12/02/SearchAndRanking/index.html"><meta property="og:site_name" content="广阔天地，大有作为"><meta property="og:description" content="搜索引擎的定义与组成在大量的文档中搜索一系列单词，根据文档与这些单词的相关程度，对搜索结果进行排名。本章中我们将将学到如何搜索引起的数据处理与数据检索的方法：数据处理：抓取网页（crawl）、建立索引（index）数据检索：从多种角度度量不同文档与搜索关键词的相关程度，根据相关程度对文档进行排序。数据处理过程目的是获取数据，并将数据存储到数据库以供检索时使用。数据检索过程是用户输入关键词，得到搜索"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="/2017/12/02/SearchAndRanking/ER.png"><meta property="og:image" content="/2017/12/02/SearchAndRanking/ER2.png"><meta property="og:image" content="/2017/12/02/SearchAndRanking/ER_LINK.png"><meta property="og:image" content="/2017/12/02/SearchAndRanking/sch.PNG"><meta property="og:image" content="/2017/12/02/SearchAndRanking/sch2.png"><meta property="og:image" content="/2017/12/02/SearchAndRanking/multiword.jpg"><meta property="og:image" content="/2017/12/02/SearchAndRanking/zuni.png"><meta property="og:image" content="/2017/12/02/SearchAndRanking/links.png"><meta property="og:updated_time" content="2017-12-12T16:45:04.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="搜索与排名"><meta name="twitter:description" content="搜索引擎的定义与组成在大量的文档中搜索一系列单词，根据文档与这些单词的相关程度，对搜索结果进行排名。本章中我们将将学到如何搜索引起的数据处理与数据检索的方法：数据处理：抓取网页（crawl）、建立索引（index）数据检索：从多种角度度量不同文档与搜索关键词的相关程度，根据相关程度对文档进行排序。数据处理过程目的是获取数据，并将数据存储到数据库以供检索时使用。数据检索过程是用户输入关键词，得到搜索"><meta name="twitter:image" content="/2017/12/02/SearchAndRanking/ER.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",version:"5.1.3",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!0},fancybox:!0,tabs:!0,motion:{enable:!1,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="laiqun.github.io/2017/12/02/SearchAndRanking/"><title>搜索与排名 | 广阔天地，大有作为</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">广阔天地，大有作为</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">你看到我的筋斗云了嘛？</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="laiqun.github.io/2017/12/02/SearchAndRanking/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="倔强的土豆"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="广阔天地，大有作为"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">搜索与排名</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-12-02T16:27:03+08:00">2017-12-02 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2017/12/02/SearchAndRanking/#comments" itemprop="discussionUrl"><span class="post-comments-count gitment-comments-count" data-xid="/2017/12/02/SearchAndRanking/" itemprop="commentsCount"></span></a></span></div></header><div class="post-body" itemprop="articleBody"><h1 id="搜索引擎的定义与组成"><a href="#搜索引擎的定义与组成" class="headerlink" title="搜索引擎的定义与组成"></a>搜索引擎的定义与组成</h1><p>在大量的文档中<strong>搜索</strong>一系列单词，根据文档与这些单词的相关程度，对搜索结果进行排名。<br>本章中我们将将学到如何搜索引起的数据处理与数据检索的方法：<br>数据处理：<strong>抓取网页</strong>（crawl）、<strong>建立索引</strong>（index）<br>数据检索：从多种角度<strong>度量</strong>不同文档与搜索关键词的<strong>相关程度</strong>，根据相关程度对文档进行排序。<br>数据处理过程目的是获取数据，并将数据存储到数据库以供检索时使用。<br>数据检索过程是用户输入关键词，得到搜索结果的过程，我们要优化搜索结果的排序，确保用户想用的文档排在首位。</p><h1 id="建立搜索引擎的步骤"><a href="#建立搜索引擎的步骤" class="headerlink" title="建立搜索引擎的步骤"></a>建立搜索引擎的步骤</h1><h2 id="数据处理"><a href="#数据处理" class="headerlink" title="数据处理"></a>数据处理</h2><p>第一步： 我们首先要有数据来供搜索引擎来检索才行，即我们要有一种收集文档的方法，也叫做网页抓取。我们先从抓取一组网页开始，然后根据这些网页内的链接逐渐抓取这些链接中的页面。<br>第二步： 为收集到的文档建立索引，因为我们要根据输入的关键字来检索文档，故这里我们将文档拆成一个个单词，创建一个单词与文档的表格。</p><table><thead><tr><th>单词</th><th>文档名</th></tr></thead><tbody><tr><td>单词1</td><td>文档1</td></tr><tr><td>单词1</td><td>文档2</td></tr><tr><td>单词2</td><td>文档2</td></tr></tbody></table><p>以上数据的含义为单词1在文档1和文档2中出现过。单词2在文档2中出现过。<br>但这里我们会发现好像漏掉了一些信息，单词的位置是对搜索结果进行排序的重要依据，比如有两篇文档，一篇文档在标题的时候就涵盖了我们要搜索的关键字，而另一篇只在末尾提到了我们要搜索的关键字，这时候，标题中包含关键字的文档往往就是我们要找的，故<strong>单词在文档中的位置</strong>是对搜索结果进行排序的一个重要指标。</p><p>我们改进一下表格的结构，添加上单词在文档中的出现的位置。值得注意的是，一个单词可能在一篇文档中被提到多次。</p><table><thead><tr><th>单词</th><th>文档名</th><th>文档位置</th></tr></thead><tbody><tr><td>单词1</td><td>文档1</td><td>第1次出现的位置</td></tr><tr><td>单词1</td><td>文档1</td><td>第2次出现的位置</td></tr><tr><td>单词1</td><td>文档1</td><td>第n次出现的位置</td></tr><tr><td>单词1</td><td>文档2</td><td>第1次出现的位置</td></tr><tr><td>单词1</td><td>文档2</td><td>第n次出现的位置</td></tr><tr><td>单词2</td><td>文档2</td><td>第1次出现的位置</td></tr></tbody></table><p>根据数据库的表格的设计原则，当一个表中的数据出现大量重复的时候，这时候往往需要拆分表格。</p><p>我们将上述表格修改为三个表格，单词表、文档名表和‘单词所处文档名与在文档中的位置描述表’。</p><img src="/2017/12/02/SearchAndRanking/ER.png" title="ER图"><p><em>上图为ER图，方形表示实体，圆圈表示属性，一个实体有多个属性。棱形表示联系，连线上的数量表示两个实体之间的关系。</em></p><p>图中有两对关系。</p><ol><li>关系1： 单词表与‘单词所处文档名与在文档中的位置描述表’两个表之间的关系是1：N，因为一个单词可以在一篇文档的多个位置出现。有了这两个表格，这样单词就不会重复书写多次啦。</li><li>关系2： 文档列表与‘单词所处文档名与在文档中的位置描述表’两个表之间的关系为1：N，因为一个文档名可能在‘单词所处文档名与在文档中的位置描述表’中被引用很多次。‘单词所处文档名与在文档中的位置描述表’中引用了文档名，如果不拆分，那么同一个文档名会被写多次。如果将文档名单独划分成一个表，引用一个文档的话只要使用文档id就可以啦，避免反复拼写完整的文档名。</li></ol><p>到目前为止，我们已经可以根据单词来检索到哪些文档中含有这些单词、以及他们在文档中的位置。</p><p>不过现在只能一次处理一个单词，而且只能以文档当初被加载的顺序返回文档。</p><p>文档的顺序还需要优化，我们需要计算搜索关键字和文档之间的相关程度，相关程度越大，就应该越靠前显示。这些将在<strong>数据检索</strong>中完成。</p><h2 id="数据检索"><a href="#数据检索" class="headerlink" title="数据检索"></a>数据检索</h2><p>第一步：数据检索即数据查询，我们要根据输入的一系列单词，返回一个经过排序的文档列表。对搜索结果进行排序，我们需要几个度量指标来量化它们与搜索关键词的匹配程度。我们将学习到不同的量化指标，比如单词频率、单词出现的位置、单词位置之间的距离（如果用户输入了多个关键词的话）、其他页面对本页面的引用次数（google的pagerank算法）等。<br>HTML页面中的链接用a标签表示，为了能够表述页面引用情况，我们要对表格关系再做修改，将链接信息单独提取出来。</p><img src="/2017/12/02/SearchAndRanking/ER2.png" title="增加衔接描述"><p>上图表示一个链接包含三个属性：衔接处的描述单词、链接来自、衔接去向。衔接处的描述单词我们可以在单词表中找到。链接来自与衔接去向可在文档列表中找到对应。一个链接可能包含多个单词描述。比如<br></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"www.google.com"</span>&gt;</span></span><br><span class="line">  google good search</span><br><span class="line"><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>上述代码中‘google’、‘good’、‘search’都指向链接到google的a标签,制作成表格如下：</p><table><thead><tr><th>单词</th><th>去哪</th></tr></thead><tbody><tr><td>google</td><td>www.google.com</td></tr><tr><td>good</td><td>www.google.com</td></tr><tr><td>search</td><td>www.google.com</td></tr></tbody></table><p>我们注意到‘去哪’所处的列有很大的重复性，‘www.google.com’被重复写了三次，这意味着我们可以拆分表格来减少冗余。<br><img src="/2017/12/02/SearchAndRanking/ER_LINK.png" title="拆分链接实体表"><br>经过上述拆分之后，我们写‘www.google.com’的时候，只需要引用它的id即可，避免了多次重复书写。</p><p>第二步：我们把搜索结果呈递给用户之后，用户会点击自己想要的链接，我们需要<strong>学习</strong>用户的点击信息来对搜索结果中文档的顺序进行调整。我们会依靠用户的点击信息来建立<strong>神经网络</strong>来优化搜索结果的排名，神经网络会学习到人们过去的点击情况。</p><h1 id="抓取数据"><a href="#抓取数据" class="headerlink" title="抓取数据"></a>抓取数据</h1><p>假设我们硬盘中没有成堆的HTML文档在等待索引，那我们就写一个简单的爬虫程序来下载HTML文档，它接收一组等待下载的网页URL，然后根据这些网站中的链接来找到其他页面，这个过程叫<strong>蛛行</strong>（Spidering）。</p><h2 id="使用urllib来下载网页"><a href="#使用urllib来下载网页" class="headerlink" title="使用urllib来下载网页"></a>使用urllib来下载网页</h2><p>urllib是一个python库，作用是方便网页下载，我们只需要传入网站的URL。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line">c=urllib.request.urlopen(<span class="string">'http://test.com'</span>)</span><br><span class="line">contents = c.read()</span><br><span class="line">print(contents[<span class="number">0</span>:<span class="number">50</span>])</span><br></pre></td></tr></table></figure><p></p><h2 id="书写爬虫"><a href="#书写爬虫" class="headerlink" title="书写爬虫"></a>书写爬虫</h2><p>这个程序使用BeautifulSoup，它能为网页建立结构化的表现形式，并且对书写不规范的页面容错性较好。<br>使用urllib和BeautifulSoup，传入一组初始的URL列表，根据URL得到网页之后，可以根据网页中的链接信息找到其他网页。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">from</span> urlparse <span class="keyword">import</span> urljoin</span><br><span class="line"><span class="comment"># 构建一个单词列表，这些单词将被忽略</span></span><br><span class="line">ingorewords=([<span class="string">'the'</span>,<span class="string">'of'</span>,<span class="string">'to'</span>,<span class="string">'and'</span>,<span class="string">'a'</span>,<span class="string">'in'</span>,<span class="string">'is'</span>,<span class="string">'it'</span>])</span><br></pre></td></tr></table></figure><p></p><p>现在，我们可以书写爬虫代码了。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">crawler</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">crawl</span><span class="params">(self,pages,depth=<span class="number">2</span>)</span>:</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(depth):</span><br><span class="line">      newpages = set()</span><br><span class="line">      <span class="keyword">for</span> page <span class="keyword">in</span> pages:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">          c = urllib.request.urlopen(page)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">          print(<span class="string">"Could not open %s"</span>% page)</span><br><span class="line">          <span class="keyword">continue</span></span><br><span class="line">        soup = BeautifulSoup(c.read()) <span class="comment"># 调用c.read()下载网页</span></span><br><span class="line">        self.addtoindex(page,soup) <span class="comment"># 下载后建立索引，这是下一小节中的函数,将在下一小节讲解</span></span><br><span class="line">        <span class="comment"># 下面我们来处理这个页面中的链接</span></span><br><span class="line">        links = soup(<span class="string">'a'</span>)</span><br><span class="line">        <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">          <span class="keyword">if</span> (<span class="string">'href'</span> <span class="keyword">in</span> dict(link.attrs)): <span class="comment">#&lt;a href=""&gt; </span></span><br><span class="line">            url = urljoin(page,link[<span class="string">'href'</span>])</span><br><span class="line">          <span class="comment">#如果有单引号，说明该url和当前的URL的根域名不是同一个域名，如 baidu.com 与jd.com</span></span><br><span class="line">            <span class="keyword">if</span> url.find(<span class="string">"'"</span>)!=<span class="number">-1</span>: </span><br><span class="line">              <span class="keyword">continue</span></span><br><span class="line">            url = url.split(<span class="string">'#'</span>)[<span class="number">0</span>] <span class="comment"># 去掉页内定位部分，url中#后为锚点</span></span><br><span class="line">            <span class="comment"># 如果是一个网页链接，并且没有被索引过</span></span><br><span class="line">            <span class="comment"># isindexed判断是否已经是否已经索引过，避免重复索引</span></span><br><span class="line">            <span class="keyword">if</span> url[<span class="number">0</span>:<span class="number">4</span>] ==<span class="string">'http'</span> <span class="keyword">and</span> <span class="keyword">not</span> self.isindexed(url): </span><br><span class="line">              newpages.add(url)</span><br><span class="line">            linkText = self.gettextonly(link) <span class="comment">#获取a标签的描述文字,这将在下一小节中讲解</span></span><br><span class="line">      <span class="comment"># page代表当前url，url代表去向，即’去哪‘，linkText为链接上的文本</span></span><br><span class="line">            self.addlinkref(page,url,linkText)  <span class="comment">#这是建立索引部分，下一小节讲解</span></span><br><span class="line">        self.dbcommit()<span class="comment"># 下一小节讲解</span></span><br><span class="line">      <span class="comment"># 输入的URL搜索完后，要根据页面中的链接来找到其他页面  </span></span><br><span class="line">      pages = newpages</span><br></pre></td></tr></table></figure><p></p><p>该函数循环遍历网页列表，并针对每个网页调用addtoindex函数。addtoindex是建立索引部分，故我们这里暂时只把url打印出来<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addtoindex</span><span class="params">(self,url,soup)</span>:</span></span><br><span class="line">  print(<span class="string">'Indexing %s'</span> % url)</span><br></pre></td></tr></table></figure><p></p><p>随后，该函数利用BeautifulSoup取到网页中的所有链接，并将这些链接加入到一个名为newpages的集合中，一组url处理完毕后，我们将得到的newpages集合复制给pages，然后开启新的循环来处理这些url。</p><p>如果你学过二叉树遍历，那么很容易就知道上述过程其实就是广度优先搜索，我们也可以将其改成递归的深度优先搜索的形式，但递归层级较深时容易导致栈溢出。</p><p>我们来测试一下上述函数:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pageslist=[<span class="string">'http://kiwitobes.com/wiki/Perl.html'</span>]</span><br><span class="line">c = crawler(<span class="string">''</span>)</span><br><span class="line">crawl(pagelist)</span><br></pre></td></tr></table></figure><p></p><h1 id="建立索引"><a href="#建立索引" class="headerlink" title="建立索引"></a>建立索引</h1><p>建立索引的过程如前文所述，我们要建立一个数据表，其中包含了不同的单词、这些单词所在的文档和单词在文档中出现的位置。</p><p>在本例中，我们真正的文本内容进行考察，忽略非文本元素（如标点符号）。将文本内容拆解为单词，并给单词建立索引。</p><p>我们将使用sqlite来建立数据库，python3的标准库中已经有这个库了。</p><p>我们修改crawler类，增加数据库操作：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sqlite3</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">crawler</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,dbname)</span>:</span></span><br><span class="line">    self.con = sqlite3.connect(dbname)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__del__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.con.close()</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">dbcommit</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.con.commit()<span class="comment"># 保存修改</span></span><br></pre></td></tr></table></figure><p></p><h2 id="设计数据库中的数据表"><a href="#设计数据库中的数据表" class="headerlink" title="设计数据库中的数据表"></a>设计数据库中的数据表</h2><p>根据前面的数据库的ER图，我们来设计数据库的表格。</p><table><thead><tr><th>表格名</th><th>表格描述</th></tr></thead><tbody><tr><td>urllist</td><td>保存已经索引过的URL列表</td></tr><tr><td>wordlist</td><td>单词列表</td></tr><tr><td>wordlocation</td><td>单词所在文档与在文档中所处的位置的列表</td></tr><tr><td>link</td><td>链接表，保存两个URL ID，指明从一个文档到另一个文档的链接关系</td></tr><tr><td>linkwords</td><td>哪些单词与链接有关</td></tr></tbody></table><img src="/2017/12/02/SearchAndRanking/sch.PNG" title="数据表设计图"><p>我们在这个图上更新一下对应关系：<br><img src="/2017/12/02/SearchAndRanking/sch2.png" title="数据表设计图"><br><em>上图链接表明，单词列表与’单词所处位置表‘的关系为1：N，即一个单词可以在文档中的多个位置出现。一个链接上可以有多个单词，所以link和linkwords的关系为1:N。文档名会被’单词所处位置表‘引用多次，所以关系为1：N。链接单词表中的单词在单词表中都能找到唯一的对应关系，故关系为1：1。链接表的的来自和去向分别对应url中的文档，故关系都是1：1。</em></p><p>所有的sqlite的表默认都有一个名为rowid的字段，故没有必要显示指定ID字段。</p><p>下面我们来写程序建立数据表：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">crawler</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">createindextables</span><span class="params">(self)</span>:</span> </span><br><span class="line">    self.con.execute(<span class="string">'create table urllist(url)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create table wordlist(word)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create table wordlocation(urlid,wordid,location)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create table link(fromid integer,toid integer)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create table linkwords(wordid,linkid)'</span>)</span><br><span class="line">    <span class="comment"># 建立索引，加快搜索速度，该操作很重要，因为数据集会很大</span></span><br><span class="line">    self.con.execute(<span class="string">'create index wordidx on wordlist(word)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create index urlidx on urllist(url)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create index wordurlidx on wordlocation(wordid)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create index urltoidx on link(toid)'</span>)</span><br><span class="line">    self.con.execute(<span class="string">'create index urlfromidx on link(fromid)'</span>)</span><br><span class="line">    self.dbcommit()</span><br></pre></td></tr></table></figure><p></p><p>测试代码，创建一个名为searchindex.db的数据库文件。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">c=crawler(<span class="string">'searchindex.db'</span>)</span><br><span class="line">c.createindextables()</span><br></pre></td></tr></table></figure><p></p><p>我们会在查询阶段再加入一张表，它根据指向该文档的其他文档(外部回指链接-inbound link)的计数情况来作为度量。</p><h2 id="在网页中查找单词"><a href="#在网页中查找单词" class="headerlink" title="在网页中查找单词"></a>在网页中查找单词</h2><p>由于网页是HTML文档，其中有大量的标签、属性、以及其他不在索引范围内的信息，而我们只需要网页中所有的文字部分即可。下面我们来编写函数，搜集所有的文本内容。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gettextonly</span><span class="params">(self,soup)</span>:</span></span><br><span class="line">  v = soup.string</span><br><span class="line">  <span class="keyword">if</span> v ==<span class="keyword">None</span>:</span><br><span class="line">    c= soup.contents</span><br><span class="line">    resulttext=<span class="string">''</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> c:</span><br><span class="line">      subtext = self.gettextonly(t)</span><br><span class="line">      resulttext=subtext+<span class="string">'\n'</span></span><br><span class="line">    <span class="keyword">return</span> resulttext</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> v.strip()</span><br></pre></td></tr></table></figure><p></p><p>该函数返回一个长字符串，其中包含了网页中的所有文字。它以递归的方式对网页中的文档对象进行遍历，寻找其中的文本节点。网页的文档分为不同的段落，保持各段落的先后顺序是很重要的。因为我们搜索时，要考虑位置信息作为度量，来优化搜索结果中的排序。<br>我们搜索的时候，是输入单词来得到结果，故我们还需要将gettextonly返回的长字符串拆成一堆独立的单词。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">separatewords</span><span class="params">(self,text)</span>:</span></span><br><span class="line">  splitter = re.compile(<span class="string">'\\W*'</span>)<span class="comment"># 以任何非字母非数字的字符作为分割符号</span></span><br><span class="line">  <span class="keyword">return</span> [s.lower() <span class="keyword">for</span> s <span class="keyword">in</span> splitter.split(text) <span class="keyword">if</span> s!=<span class="string">''</span>]<span class="comment"># 去掉空单词</span></span><br></pre></td></tr></table></figure><p></p><p>由于上述拆分单词的方式把任何非字母非数字的字符都看做分隔符，对于英文单词的提取不会有问题，但这种形式无法正确处理类似“c++”这样的词汇，要完美的抽取单词并非一件简单的事，已经有大量的相关研究来改进这项技术。</p><blockquote><p>提示：我们可以使用词干提取法(Stemming algorithm)来去掉单词的后缀。词干提取算法试图将单词转换成对应的词干。例如：将单词“indexing”变成“index“。这样，人们在搜索”index“时也会得到包含单词”indexing“的文档。什么时候使用呢？ 我们可以在检索文档的时候提取单词的词干，也在在搜索时提取用户输入的查询词的词干。我们可以在<a href="http://www.tartarus.org/~martin/PorterStemmer/index.html" target="_blank" rel="noopener">Porter Stemmer</a> 找到一个很有名的词干提取算法的Python实现——Porter Stemmer。</p></blockquote><h2 id="加入索引"><a href="#加入索引" class="headerlink" title="加入索引"></a>加入索引</h2><h3 id="将普通文本加入索引"><a href="#将普通文本加入索引" class="headerlink" title="将普通文本加入索引"></a>将普通文本加入索引</h3><p>得了一个出现于网页中单词的列表之后，我们应该讲这些单词都加入到数据库中，并加入索引，在网页文档和单词之间建立关联，并保存单词在文档中出现的位置。在本文中，单词的位置就是其在单词列表中的序号。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addtoindex</span><span class="params">(self,url,soup)</span>:</span></span><br><span class="line">  <span class="keyword">if</span> self.isindexed(url): <span class="keyword">return</span> <span class="comment"># 如果这个网页文档已经处理过了，略过</span></span><br><span class="line">  print(<span class="string">"indexing "</span>+url)</span><br><span class="line">  <span class="comment">#获得网页中的所有文本，并将其拆解为单词</span></span><br><span class="line">  text = self.gettextonly(soup)</span><br><span class="line">  words = self.separatewords(text)</span><br><span class="line">  <span class="comment"># 得到网页文档（用url来标识）的id，</span></span><br><span class="line">  <span class="comment"># getentryid返回文档在文档表中的id，如果不存在则文档表中新建一条记录，并将其ID返回</span></span><br><span class="line">  urlid = self.getentryid(<span class="string">'urllist'</span>,<span class="string">'url'</span>,url)<span class="comment"># 参数分别代表： 数据库中的表格名 字段 值</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 将每个单词加入数据库，并与文档进行管理</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(len(words)):</span><br><span class="line">    word = words[i]</span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">in</span> ingorewords:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    wordid = self.getentryid(<span class="string">'wordlist'</span>,<span class="string">'word'</span>,word)<span class="comment"># 将单词加入数据库中的单词表</span></span><br><span class="line">    <span class="comment"># 填充单词的所在文档与单词在文档位置表</span></span><br><span class="line">    self.con.execute(<span class="string">"insert into wordlocation(urlid,wordid,location)  values (%d,%d,%d)"</span> % (urlid,wordid,i))</span><br></pre></td></tr></table></figure><p></p><p>我们还需要写出两个辅助函数，getentryid和isindexed.</p><p>getentryid的作用是返回某个条目的ID，如果条目不存在，就会在相应的表中插入一条新纪录，并将ID返回。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getentryid</span><span class="params">(self,table,field,value)</span>:</span></span><br><span class="line">  cur = self.con.execute(<span class="string">"select rowid form %s where %s='%s' "</span> % (table,field,value))</span><br><span class="line">  res = cur.fetchone()</span><br><span class="line">  <span class="keyword">if</span> res == <span class="keyword">None</span>:</span><br><span class="line">    cur = self.con.execute(<span class="string">"insert into %s (%s) values ('%s') "</span>% (table,field,value))</span><br><span class="line">    <span class="keyword">return</span> cur.lastrowid</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">return</span> res[<span class="number">0</span>]</span><br></pre></td></tr></table></figure><p></p><p>isindexed 函数是判断网页文档是否加入了文档表中，如果在文档表中，判断是否与任何单词关联，如果没有关联，则认为该网页文档未被索引。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">isindexed</span><span class="params">(self,url)</span>:</span></span><br><span class="line">  u = self.con.execute(<span class="string">"select rowid from urllist where url='%s' "</span> % url).fetchone()</span><br><span class="line">  <span class="keyword">if</span> u!=<span class="keyword">None</span>:</span><br><span class="line">    <span class="comment"># 检查是否有单词与这个文档关联</span></span><br><span class="line">    v = self.con.execute(<span class="string">"select * from wordlocation where urlid=%d"</span> %u[<span class="number">0</span>]).fetchone()</span><br><span class="line">    <span class="keyword">if</span> v!=<span class="keyword">None</span>:</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">True</span></span><br><span class="line">  <span class="keyword">return</span> <span class="keyword">False</span></span><br></pre></td></tr></table></figure><p></p><h3 id="将链接处的文本加入索引"><a href="#将链接处的文本加入索引" class="headerlink" title="将链接处的文本加入索引"></a>将链接处的文本加入索引</h3><p>由于pagerank算法参照了文档中的链接来优化搜索结果，故我们需要对链接文本进行记录。<br>这里先举个例子：<br></p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"www.google.com"</span>&gt;</span>google good search<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>我们要处理这个链接，步骤是：</p><ol><li>将单词分解为3个单词，分别是google、good、search</li><li>获取当前的url（代表from）和这个链接指向的url(www.google.com)</li><li>如果链接是到自身的，什么都不操作</li><li>将from和to的关系插入到link表，返回该条目的序号</li><li>将第一步得到的3个单词插入到linkwords，将每个单词与第四步中返回的序号关联</li></ol><p>我们将上述的步骤写成代码:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">addlinkref</span><span class="params">(self,urlFrom,urlTo,linkText)</span>:</span></span><br><span class="line">  words = self.separatewords(linkText)</span><br><span class="line">  fromid = self.getentryid(<span class="string">'urllist'</span>,<span class="string">'url'</span>,<span class="string">'urlFrom'</span>)</span><br><span class="line">  toid = self.getentryid(<span class="string">'urllist'</span>,<span class="string">'url'</span>,<span class="string">'urlTo'</span>)</span><br><span class="line">  <span class="keyword">if</span> fromid == toid:</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  cur = self.con.execute(<span class="string">"insert into link(fromid,toid) values(%d,%d)"</span> % (fromid,toid))</span><br><span class="line">  linkid = cur.lastrowid</span><br><span class="line">  <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    <span class="keyword">if</span> word <span class="keyword">in</span> ignorewords:</span><br><span class="line">      <span class="keyword">continue</span></span><br><span class="line">    wordid = self.getentryid(<span class="string">'wordlist'</span>,<span class="string">'word'</span>,word)</span><br><span class="line">    self.con.execute(<span class="string">"insert into linkwords (linkid,wordid) values(%d,%d)"</span> % (linkid,wordid))</span><br></pre></td></tr></table></figure><p></p><h3 id="测试加入索引功能"><a href="#测试加入索引功能" class="headerlink" title="测试加入索引功能"></a>测试加入索引功能</h3><p>再次执行crawler，现在已经将网页的内容添加到数据库并建立索引了。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pageslist=[<span class="string">'http://kiwitobes.com/wiki/Perl.html'</span>]</span><br><span class="line">c = crawler(<span class="string">'searchindex.db'</span>)</span><br><span class="line">crawl(pagelist)</span><br></pre></td></tr></table></figure><p></p><p>craler可能会运行较长时间，我们可以下载一份已经加载好的serachindex.db。</p><p>我们可以通过数据库查询操作，来得知检索的结果。下面我们试着检查某个单词的对应条目<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[row <span class="keyword">for</span> row <span class="keyword">in</span> crawerler.con.execute(<span class="string">'select urlid from wordlocation where wordid=1 '</span>)]</span><br><span class="line"><span class="comment"># 返回[(1,),(46),....]</span></span><br></pre></td></tr></table></figure><p></p><p>此处返回的包含单词id为1的所有文档的列表，这表示我们已经成功的进行了一次全文搜索。不过现在的代码只能输入一个单词来检索，而且只能够按照文档当初被加入索引的顺序来返回文档。<br>下面我们会扩展查询功能，实现可以同时查找多个单词。</p><h1 id="查询"><a href="#查询" class="headerlink" title="查询"></a>查询</h1><p>现在我们有了crawler程序来下载网页文档，并将网页文档加入到数据库。接下来应该实现的是搜索（查询）的部分了。我们来新建一个用于搜索的类。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">searcher</span>:</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,dbname)</span>:</span></span><br><span class="line">    self.con = sqlite.connect(dbname)</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__del__</span><span class="params">(self)</span>:</span></span><br><span class="line">    self.con.close()</span><br></pre></td></tr></table></figure><p></p><p>wordlocation数据表提供了单词与文档的联系。<br>上一节中我们实现了一个单词的搜索，下面我们来实现多个单词的同时搜索。<br>我们要写一个查询函数，接受一个查询字符串作为参数，我们需要将查询字符串拆分为多个单词，然后构造一个sql查询语句，只查找包含所有查询词的文档。<br>问题是怎样实现多词查找呢？ 这里先举个例子：<br>假设我们要做一个涉及三个单词的查找：单词id为10号和17号和21号。<br><img src="/2017/12/02/SearchAndRanking/multiword.jpg" title="三个单词的查找"><br>我们为每个单词建立一个wordlocation的表的引用，分别是w0，w1，w2。由于3个单词必须在一个文档中全部包含，故这三个词的urlid必须相同，如图上的虚线的箭头所示的那样。因为为wordlocation表的不同引用，故urlid必须相同这个条件可以写为”where w0.urlid=w1.urlid=w2.urlid”。<br>然后我们便可以写出如下完整的sql语句。<br></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> w0.urlid,w0.location,w1.location,w2.location </span><br><span class="line"><span class="keyword">from</span> wordlocation w0,wordlocation w1,wordlocation w2 </span><br><span class="line"><span class="keyword">where</span> w0.urlid=w1.urlid=w2.urlid </span><br><span class="line"><span class="keyword">and</span> w0.wordid=<span class="number">10</span> <span class="keyword">and</span> w1.wordid=<span class="number">17</span> <span class="keyword">and</span> w2.wordid=<span class="number">21</span></span><br><span class="line"><span class="comment">/*返回示例[(1,327,23,33),(1,327,23,39),(1,327,23,143) 等等]*/</span></span><br><span class="line"><span class="comment">/*每一项的含义为(文档名id，单词1位置，单词2位置，单词3位置)*/</span></span><br><span class="line"><span class="comment">/*也可以写作*/</span></span><br><span class="line"><span class="keyword">select</span> w0.urlid,w0.location,w1.location,w2.location </span><br><span class="line"><span class="keyword">from</span> wordlocation w0,wordlocation w1,wordlocation w2 </span><br><span class="line"><span class="keyword">where</span> w0.urlid=w1.urlid </span><br><span class="line"><span class="keyword">and</span> w0.wordid=<span class="number">10</span> <span class="keyword">and</span> w1.wordid=<span class="number">17</span> </span><br><span class="line"><span class="keyword">and</span> w1.urlid = w2.urlid <span class="keyword">and</span> w2.wordid=<span class="number">21</span></span><br></pre></td></tr></table></figure><p></p><p>我们注意到，根据单位位置的不同组合，每个网页文档的id会返回多次。上述结果返回的都是文档1中三个单词的不同位置的组合。<br>我们来写程序，来自动根据输入单词的个数来建立可以同时查询多词的sql语句。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getmatchrows</span><span class="params">(self,q)</span>:</span></span><br><span class="line">  <span class="comment"># 构造查询字符串</span></span><br><span class="line">  fieldlist = <span class="string">'w0.urlid'</span> <span class="comment">#要得到的结果字段</span></span><br><span class="line">  tablelist = <span class="string">''</span> <span class="comment">#要建立的引用表的个数，2个单词的情况下，wordlocation的三个引用分别为w0，w1</span></span><br><span class="line">  clauselist=<span class="string">''</span> <span class="comment"># where后的条件限定字符串</span></span><br><span class="line">  wordids=[]</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 根据空格拆分单词</span></span><br><span class="line">  words = s.split(<span class="string">' '</span>)</span><br><span class="line">  tablenumber = <span class="number">0</span> <span class="comment"># 要构建的引用表的数量，为查询单词的数量</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">    <span class="comment"># 获取单词的id</span></span><br><span class="line">    wordrow = self.con.execute(<span class="string">"select rowid from wordlist where word=%s"</span> % word).fetchone()</span><br><span class="line">    <span class="keyword">if</span> wordrow!=<span class="keyword">None</span>:</span><br><span class="line">      wordid=wordrow[<span class="number">0</span>]</span><br><span class="line">      wordids.append(wordid)</span><br><span class="line">      <span class="keyword">if</span> tablenumber&gt;<span class="number">0</span>:</span><br><span class="line">        tablelist = <span class="string">','</span></span><br><span class="line">        clauselist+=<span class="string">' and '</span></span><br><span class="line">        clauselist+=<span class="string">'w%d.urlid=w%d.urlid and '</span> % (tablenumber<span class="number">-1</span>,tablenumber)</span><br><span class="line">      fieldlist+= <span class="string">',w%d.location'</span> % tablenumber</span><br><span class="line">      tablelist+=<span class="string">'wordlocation w%d'</span> % tablenumber</span><br><span class="line">      clauselist+=<span class="string">'w%d.wordid=%d'</span> % (tablenumber,wordid)</span><br><span class="line">      tablenumber+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># 根据各个组成部分，构建查询语句</span></span><br><span class="line">  fullquery = <span class="string">'select %s from %s where %s'</span> % (fieldlist,tablelist,clauselist)</span><br><span class="line">  cur = self.con.execute(fullquery)</span><br><span class="line">  rows = [row <span class="keyword">for</span> row <span class="keyword">in</span> cur]</span><br><span class="line">  <span class="keyword">return</span> rows,wordids</span><br></pre></td></tr></table></figure><p>此时我们已经可以同时搜索多个单词，下面我应该考虑几种度量方法，来读搜索结果进行排序。<br>本文中会介绍三种度量方法：</p><ol><li>基于内容的排名法(Content-based ranking) 该方法主要根据网页的内容，利用某些可行的度量方式对查询结果进行判断。</li><li>基于外部回指链接的排名法(Inbound-link ranking) 利用网页之间的链接结构来决定查询结果中各个文档的重要性。</li><li>利用人民搜索时，对搜索结果的实际点击情况，进行关联学习的神经网络方法。</li></ol><h2 id="基于内容的排名"><a href="#基于内容的排名" class="headerlink" title="基于内容的排名"></a>基于内容的排名</h2><p>到目前为止，我们已经成功获得了与查询条件相匹配的网页。不过，其返回结果的排列顺序却很简单，即其被检索时的顺序。<br>我们需要在大量提及到你查询词的网页中，逐一的浏览直到你找到真正想要的页面。<br>为了解决这一问题，我们需要一种对网页评分的方法，并将评价最高的网页排在最前面。<br>本小节将提到3种基于查询词与文档内容的相关程度来计算评分的方法。分别是：</p><ol><li>单词频度 查询条件中的单词在文档中出现的次数有助于我们判断文档的相关程度。</li><li>文档位置 文档的主题一般会在文档的开始处出现。</li><li>单词距离 如果查询条件中有多个单词，在文档中它们之间的位置应该很近。</li></ol><p>我们将会使用3个度量做为对搜过结果的排序依据。这里，我们写一个方法，来调用这三个函数,并对这3种度量方法加上一个权重。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># getscroedlist是调用3个评价函数，将将这3个评价函数的评分按权重加起来</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getscoredlist</span><span class="params">(self,rows,wordids)</span>:</span></span><br><span class="line">  <span class="comment"># rows种的数据项格式为rows[0]为url row[1]为第一个单词的位置</span></span><br><span class="line">  totalscores = dict([(rows[<span class="number">0</span>],<span class="number">0</span>) <span class="keyword">for</span> row <span class="keyword">in</span> rows])</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 调用评价函数的地方</span></span><br><span class="line">  weights=[]<span class="comment">#每一项的格式为(权重，调用评价函数后的评分)</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (weight,scores) <span class="keyword">in</span> weights:</span><br><span class="line">    <span class="keyword">for</span> url <span class="keyword">in</span> totalscores:</span><br><span class="line">      totalscores[url]+=weight*scores[url]</span><br><span class="line">  <span class="keyword">return</span> totalscores</span><br><span class="line"><span class="comment">#根据文档的id获取文档完整的url</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">geturlname</span><span class="params">(self,id)</span>:</span></span><br><span class="line">  <span class="keyword">return</span> self.con.execute(<span class="string">"select url from urllist where rowid=%d"</span> % id).fetchone[<span class="number">0</span>]</span><br><span class="line"><span class="comment">#查询函数的实现</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">query</span><span class="params">(self,q)</span></span></span><br><span class="line">  rows,wordids=self.getmatchrows(q)</span><br><span class="line">  scores=self.getscoredlist(rows,wordids)</span><br><span class="line">  rankedscores=sorted([(score,url) <span class="keyword">for</span> (url,score) <span class="keyword">in</span> scores.items()],reverse=<span class="number">1</span>)</span><br><span class="line">  <span class="keyword">for</span> (score,urlid) <span class="keyword">in</span> rankedscores[<span class="number">0</span>:<span class="number">10</span>]: <span class="comment"># 只取评分最高的前10个</span></span><br><span class="line">    print(<span class="string">"%f\t%s"</span> % (score,self.geturlname(urlid)))</span><br></pre></td></tr></table></figure><p></p><p>query方法调用的 getscoredlist 还没有调用任何评价方法，但是它已经可以打印出评分和url。<br>格式为:<br>网页1的评分 网页1<br>网页2的评分 网页2</p><h3 id="归一化的方法"><a href="#归一化的方法" class="headerlink" title="归一化的方法"></a>归一化的方法</h3><p>在书写各个评价方法的函数之前，我们提前想一下，给予单词频度的方法，单词出现的次数越多表明相关程度越大；而基于单词位置的方法，是单词越靠前越大，也就是代表位置的数据越小越好。<br>为了对不同方法的返回结果进行比较，我们需要一种归一化方法，即，使它们有相关的值域和统一的方向，比如：这些评价函数都是值越大越好，为了做到这点，我们可以给单词位置函数的调用结果取个倒数。<br>该函数接受一个代表文档的id和文档评分的字典为参数，指明了值越大越好还是越小越好之后，调用该函数会返回一个带有相同文档id，评价值介于0到1之间的新字典。<br>函数根据每个评价值与最佳结果的接近程度，对各个记录做了缩放处理。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalizescores</span><span class="params">(self,scores,smallIsBetter=<span class="number">0</span>)</span>:</span></span><br><span class="line">  vsmall = <span class="number">0.00001</span><span class="comment"># 避免除数为0</span></span><br><span class="line">  <span class="keyword">if</span> smallIsBetter:<span class="comment"># 如果数字越小越好，则取分数的倒数，由于评分最低应该划分到1，故乘上最小值</span></span><br><span class="line">    minscore = min(scores.values()) </span><br><span class="line">    <span class="comment"># 下一行中的max是为了避免除数为0的问题</span></span><br><span class="line">    <span class="keyword">return</span> dict([(url,float(minscore)/max(vsmall,score) ) <span class="keyword">for</span> (url,score) <span class="keyword">in</span> scores.items()])</span><br><span class="line">  <span class="keyword">else</span>:<span class="comment"># 如果是越大越好，每个数都和最大值相除</span></span><br><span class="line">    maxscore = max(scores.values())</span><br><span class="line">    <span class="keyword">if</span> maxscore==<span class="number">0</span>:</span><br><span class="line">      maxscore=vsmall</span><br><span class="line">    <span class="keyword">return</span> dict([(url,float(score)/maxscore ) <span class="keyword">for</span> (url,score) <span class="keyword">in</span> scores.items()])</span><br></pre></td></tr></table></figure><p></p><p>每个评价函数都会调用该函数，将结果进行归一化处理，得到一个介于0-1之间的值。</p><h3 id="单词频度"><a href="#单词频度" class="headerlink" title="单词频度"></a>单词频度</h3><p>这种方法以单词频度作为度量手段，根据查询条件中的单词在网页中出现的次数对网页进行评分。<br>假如搜索“python”，我们更希望得到的是一个内容中多次提到该单词的页面，比如有关python语言的网页；而不是一个关于某个音乐家的网页，可能这位音乐家在文章的末尾处偶尔提到了他有一条宠物蟒蛇(英文是：python)。<br>我们来编写函数实现这个功能：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">frequencyscore</span><span class="params">(self,rows)</span>:</span></span><br><span class="line">  counts=dict([(row[<span class="number">0</span>],<span class="number">0</span>)<span class="keyword">for</span> row <span class="keyword">in</span> rows])<span class="comment"># rows中的每一项格式为： url 单词1出现位置 单词2出现位置</span></span><br><span class="line">  <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">    counts[row[<span class="number">0</span>]]+=<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> self.normalizescores(counts)</span><br></pre></td></tr></table></figure><p></p><p>该函数创建了一个字典，其键为网页文档的URL，值为该文档中‘包含查询单词的’单词数量。最后进行归一化处理，在本例中，分值越大越好。<br>我们修改getscoredlist的weights一行:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weights=[(<span class="number">1.0</span>,self.frequencyscore(rows))]</span><br></pre></td></tr></table></figure><p></p><p>测试一下效果:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">e=searcher(<span class="string">'searchindex.db'</span>)</span><br><span class="line">e.query(<span class="string">'functional programming'</span>)</span><br><span class="line"><span class="comment">#1.000000 http://kiwitobes.com/wiki/Functional_programming.html</span></span><br><span class="line"><span class="comment">#0.262476 http://kiwitobes.com/wiki/Categorical_list_of_programming_languages.html 0.062310 #http://kiwitobes.com/wiki/Programming_language.html</span></span><br><span class="line"><span class="comment">#0.043976 http://kiwitobes.com/wiki/Lisp_programming_language.html</span></span><br><span class="line"><span class="comment">#0.036394 http://kiwitobes.com/wiki/Programming_paradigm.html</span></span><br></pre></td></tr></table></figure><p></p><p>上述返回结果中”Functional programming”的网页放在了最前面，后面是另外几个相关的网页，从结果中我们可以查出，“function programming”的评分结果是其他评分结果的4倍。大多数的搜索引擎不会将最终的评价结果给用户，但这些评分信息是很重要的。利用评分信息，我们可以设定仅仅显示评分超过某个阈值的网页；我们也可以根据网页的相关程度，按一定比例的字体太小来显示不同条目。</p><h3 id="单词位置"><a href="#单词位置" class="headerlink" title="单词位置"></a>单词位置</h3><p>另一个判断网页与查询条件相关程度的简单度量方法，是搜索单词在网页中的位置。<br>通常，如果一个网页与待搜索的单词相关，则该单词就更有可能在靠近网页开始处的位置出现，甚至出现在标题中。<br>利用这一点，搜索引擎可以待查单词出现越早的情况给予越高的评价。<br>由于我们建立索引时保持了单词的位置信息，现在我们可以利用位置信息来评价网页了。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">locationscore</span><span class="params">(self,rows)</span>:</span><span class="comment"># rows的每一项格式为：网页URL 单词1出现的位置 单词2出现的位置 ...</span></span><br><span class="line">  locations = dict([(row[<span class="number">0</span>],<span class="number">100000</span>) <span class="keyword">for</span> row <span class="keyword">in</span> rows])<span class="comment">#1000000代表默认的最靠后的位置</span></span><br><span class="line">  <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">    loc = sum(row[<span class="number">1</span>:])<span class="comment">#这里将一个单词的所有位置的序号都加起来。</span></span><br><span class="line">    <span class="keyword">if</span> loc&lt;locations[row[<span class="number">0</span>]]:</span><br><span class="line">      locations[row[<span class="number">0</span>]] = loc</span><br><span class="line">  <span class="keyword">return</span> self.normalizescores(locations,smallIsBetter=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>一个文档中的一个单词可能会多次出现，我们计算一个文档中的一个单词的出现的所有位置之和，作为度量，将这个结果和过去最好的结果进行比较判断，得到一个单词的位置信息之和改为最小的。我们对结果进行归一化，smallIsBetter意味着，位置之和最小的网页或的评价值为1.0。<br>我们修改getscoredlist的weights一行:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weights=[(<span class="number">1.0</span>,self.locationscore(rows))]</span><br></pre></td></tr></table></figure><p></p><p>测试一下效果:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">e=searcher(<span class="string">'searchindex.db'</span>)</span><br><span class="line">e.query(<span class="string">'functional programming'</span>)</span><br></pre></td></tr></table></figure><p></p><p>到目前为止，我们所介绍的所有度量方法中，没有任何一种方式对于每一种情况而言都是最有的。对于搜索者而言，各种度量方法都是有效的；而在一组特定的文档中，为了给出最佳结果，不同的加权组合也是必要的。我们可以对weights一行按照如下的方式修改，为两种不同的度量分配不同的权重。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weights =[(<span class="number">1.0</span>,self.frequencyscore),(<span class="number">1.5</span>,self.locationscore)]</span><br></pre></td></tr></table></figure><p></p><p>请尝试不同权重和查询，看看对查询结果的影响如何。<br>相对于单词频度，单词位置信息更难以作假，我们可以在文档的开始处不断重复待查询的单词，但这对基于单词位置的度量方法影响很小。</p><h3 id="单词距离"><a href="#单词距离" class="headerlink" title="单词距离"></a>单词距离</h3><p>当查询中包含多个单词时，寻找单词彼此之间距离很近的网页往往是有意义的。<br>大多数时候在进行多次查询时，人们时常会关注于哪些在概念意义上与这些词有关联的网页。<br>这和搜索引擎的引号用法相同，双引号代表仅显示完全匹配结果，搜索出来的信息要包含所有查询词，而且顺序也必须保持一致，而且查询词之间不能夹带任何额外的单词。<br>在这里，我们使用一种较为宽松的度量，允许单词的顺序与查询词的顺序不一致，也允许其中间夹带其他的单词。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distancescore</span><span class="params">(self,rows)</span>:</span></span><br><span class="line">  <span class="comment">#rows每一项的格式为：url 单词1出现的位置 单词2出现的位置</span></span><br><span class="line">  <span class="comment"># 如果用户输入只有一个单词的情况,rows[0] 此时情况为(url,单词1位置)</span></span><br><span class="line">  <span class="keyword">if</span> len(rows[<span class="number">0</span>]&lt;=<span class="number">2</span>):</span><br><span class="line">  <span class="comment"># 只有一个单词，所有文档的得分都一样</span></span><br><span class="line">    <span class="keyword">return</span> dict([(row[<span class="number">0</span>],<span class="number">1.0</span>) <span class="keyword">for</span> row <span class="keyword">in</span> rows])</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 初始化字典，填入一个很大的数作为初始值</span></span><br><span class="line">  mindistance = dict([(rows[<span class="number">0</span>],<span class="number">1000000</span>) <span class="keyword">for</span> row <span class="keyword">in</span> rows])</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">    dist=sum([  abs(row[i]-row[i<span class="number">-1</span>]) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>,len(row))  ])</span><br><span class="line">    <span class="keyword">if</span> dist&lt;mindistance[row[<span class="number">0</span>]]:</span><br><span class="line">      mindistance[row[<span class="number">0</span>]]=dist</span><br><span class="line">  <span class="keyword">return</span> self.normalizescores(mindistance,smallIsBetter=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p></p><p>当函数遍历单词位置时，它会计算处每个单词位置和上一个单词位置之间的差距。<br>由于查询会遍历每一种距离组合，因此函数将确保找出总距离的最小值。<br>我们修改getscoredlist的weights一行来测试这个度量方法，不过建议将该度量方法与其他度量组合使用，才能取得更好的效果。</p><h2 id="基于外部回指链接的排名"><a href="#基于外部回指链接的排名" class="headerlink" title="基于外部回指链接的排名"></a>基于外部回指链接的排名</h2><p>前面我们介绍的方法都是基于网页中的文本内容的。尽管许多搜索引擎依然采用这些方法，但如果我们能够参照其他网站对目标网站的引用情况时，搜索结果会被进一步改善。<br>我们会考察哪些网站链接到了目标网站，以及他们对网页的评价来作为度量。<br>这种方法对于屏蔽一些垃圾网站和钓鱼网站特别管用，因为和有意义的网站和真实网站相比，这些网页被其他网站引用的可能性很小。<br>前面我们已经对链接处的文本进行了特殊处理——links表记录了‘来源’和‘去处’的相应的文档的URL ID，而且linkswords还记录了单词与链接的关联。<br>我们会考察外部回指链接的数量和质量。即这个网页被其他网站引用的数量的多少；这个网站被知名的大网站引用的情况如何（因为如果一个权威网站引用的网页，其网页的质量一般会比较好）。</p><h3 id="数量上–简单计数"><a href="#数量上–简单计数" class="headerlink" title="数量上–简单计数"></a>数量上–简单计数</h3><p>这是一种很简单的做法，统计一下有几个网站引用了目标页面即可。<br>科研论文的评价就是采用这种方式，人们将论文的重要程度与该论文的被引用次数进行关联，论文被引用的次数越多，表明这篇论文的重要程度越高。<br>下面，我们书写函数，统计links表中每个页面没引用的次数，然后建立起一个键为网页的URL ID，值为被引用次数的字典。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inboundlinkscore</span><span class="params">(self,rows)</span>:</span></span><br><span class="line">  uniqueurls = set([row[<span class="number">0</span>] <span class="keyword">for</span> row <span class="keyword">in</span> rows])<span class="comment"># 使用set来去重</span></span><br><span class="line">  inboundcount = dict([  (url,self.con.execute(<span class="string">' \</span></span><br><span class="line"><span class="string">  select count(*) from link where toid=%d'</span> %url).fetchone()[<span class="number">0</span>])  \</span><br><span class="line">  <span class="keyword">for</span> url <span class="keyword">in</span> uniqueurls ])</span><br><span class="line">  <span class="keyword">return</span> self.normalizescores(inboundcount)</span><br></pre></td></tr></table></figure><p></p><p>该方法对于符合查询条件的所有网页，根据外部回指链接数进行排序。可见，这种方法是有前提的，即我们必须先得到符合查询条件的所有网页，然后才能通过网页的被引用数来对结果进行排序。所以，我们需要将该方法集合先前介绍的任何一种度量方法一起使用。<br>上述统计方法对于所有的外部回指链接都使用了相同的权重，但这种方法存在问题，如果一个人想故意刷排名的话，他只需要建立起很多站点，然后引用他想提高排名的网站即可。<br>我们也会发现，一些被权威网站引用的网页，往往会是我们感兴趣的网站，对于权威网站上被引用的网页，我们应该给与更高的权重值才合理。</p><h3 id="质量上–pagerank算法"><a href="#质量上–pagerank算法" class="headerlink" title="质量上–pagerank算法"></a>质量上–pagerank算法</h3><p>PageRank算法是由Google的创始人发明的，现在基于这一思路的各种变体已经被所有大型的搜索引擎采用。<br>该算法为每个网页都赋予了一个指示网页重要程度的评价值。<br>网页的重要性的评价依据是指向该网页的其它网站的重要性，以及这些网页中所包含的连接数求得。</p><blockquote><p>PageRank计算的是某个人在任意次链接单击之后到达想要页面的可能性。如果一个页面被很多热门网站引用，那么用户很有可能“很幸运的”发现这个网页。如果用户不停的单击，他们会把每个页面都点击一遍，但大多数人，经过一定次数的点击，找到自己想要的页面后，就不再点击链接来跳转到其他页面了。为了反映这一情况，PageRank算法使用了一个值为0.85的阻尼因子，用来指示用户持续点击每个网页中链接的概率为85%。<br><img src="/2017/12/02/SearchAndRanking/zuni.png" title="阻尼系数的含义"><br>上图中，我们用位于中心的最小的圆视为初始页面，用户点击当前页面的链接的概率为0.85，此时到达了一个新的页面，然后那个新页面中的链接到达其他的页面的概率也是0.85，而相对于初始页面，我们点击到第二层的概率为0.85*0.85=0.7225，经过不断的点击到达新页面，那么从初始页面到这个新页面的概率要不断的乘0.85，直到为接近0，此时便可以视为用户停止点击。<br>下面，我们展示一组网页之间链接的例子，来表述PageRank评分的计算方法：<br><img src="/2017/12/02/SearchAndRanking/links.png" title="计算A的PageRank值"><br>A、B、C、D代表4个页面，箭头表示它们的链接。网页B、C、D都指向了A，它们的PageRank值已经计算得出。<br>B除了指向A之外，还指向其它的3个页面；C除了指向A之外，还指向其它4个页面；D只指向A。<br>为了得到A的PageRank值，我们将指向A页面的每个网页的PageRank(PR)评分除上这些网页中的链接总数，然后将这个数字乘上阻尼因子0.85,再加上0.15的最小值。<br>PR(A)的计算公式如下所示：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PR(A)=<span class="number">0.15</span>+<span class="number">0.85</span>*(  PR(B)/links(B)+PR(C)/links(C)+PR(D)/links(D)  )</span><br><span class="line">     =<span class="number">0.15</span>+<span class="number">0.85</span>*(  <span class="number">0.5</span>/<span class="number">4</span> + <span class="number">0.7</span>/<span class="number">5</span> +<span class="number">0.2</span>/<span class="number">1</span>  )</span><br><span class="line">     =<span class="number">0.15</span>+<span class="number">0.85</span>(<span class="number">0.125</span>+<span class="number">0.14</span>+<span class="number">0.2</span>)</span><br><span class="line">     =<span class="number">0.15</span>+<span class="number">0.85</span>*<span class="number">0.465</span></span><br><span class="line">     =<span class="number">0.54525</span></span><br></pre></td></tr></table></figure><p></p></blockquote><p>我们发现，D只指向A，所以D贡献了全部都PageRank分值给A，尽管D相比对B或C的PageRank评分较低，但D对A的PageRank评分值贡献最大，为0.2；而B贡献了0.125，C贡献了0.14。<br>很简单的计算方法吧！ 不过还有一个问题，在计算A的PageRank评分之前，指向A的网页都已经有了PageRank评分。换句话说，在计算一个网页的PageRank评分时，必须提前得知指向这个网页的其他网页的PageRank评分才行。<br>那么如何对一组还没有PageRank评分值的网页进行PageRank计算呢?<br>为了解决这个问题，我们可以先为所有的页面设置一个随机的PageRank评分。由于比较热门的网站，很多网站会引用它；那么计算PageRank评分的时候，热门网站的分值会提高。修正了PageRank评分之后，我们再迭代这一过程，PageRank的评分又会被修正一些，这样每个网页的PageRank评分会慢慢接近真实值。<br>PageRank的计算是一项耗时的工作，而且计算结果不会因为查询条件的变化而变化，所以，我们可以建立一个函数为每个URL提前计算PageRank评分，并将评分数据放入到数据表中。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">calculatepagerank</span><span class="params">(self,iterations=<span class="number">20</span>)</span>:</span></span><br><span class="line">  <span class="comment"># 清除现有的PageRank表</span></span><br><span class="line">  self.con.execute(<span class="string">'drop table if exists pagarank'</span>)</span><br><span class="line">  self.con.execute(<span class="string">'create table pagerank(urlid primary key,score)'</span>)</span><br><span class="line">  <span class="comment"># 初始化每个url，将其PageRank值设置为1（初始化为多少都可以，如果迭代次数足够多，PageRank评分会慢慢接近真实值）</span></span><br><span class="line">  self.con.execute(<span class="string">'insert into pagerank select rowid,1.0 from urllist'</span>)</span><br><span class="line">  self.dbcommit()</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(iterations):</span><br><span class="line">    print(<span class="string">'Iteration %d'</span> % i)</span><br><span class="line">    <span class="keyword">for</span> (urlid,) <span class="keyword">in</span> self.con.execute(<span class="string">'select rowid from urllist'</span>):</span><br><span class="line">      pr = <span class="number">0.15</span> <span class="comment"># 最小值，85%的概率可能继续点击，15%的概率不会再点击</span></span><br><span class="line">      <span class="comment">#获得引用过当前页面的所有其他页面</span></span><br><span class="line">      <span class="keyword">for</span> (linker,) <span class="keyword">in</span> self.con.execute(<span class="string">'select distinct fromid from link where toid=%d'</span> %urlid):</span><br><span class="line">        <span class="comment">#得到‘其他页面’的PageRank评分</span></span><br><span class="line">        linkingpr=self.con.execute(<span class="string">'select score from pagerank where urlid=%d'</span> % linker).fetchone()[<span class="number">0</span>]</span><br><span class="line">        <span class="comment">#得到‘其他页面’的总链接数</span></span><br><span class="line">        linkingcount=self.con.execute(<span class="string">'select count(*) from link where fromid=%d'</span> %d linker).fetone()[<span class="number">0</span>]</span><br><span class="line">        pr+=<span class="number">0.85</span>*(linkingpr/linkingcount)</span><br><span class="line">      self.con.execute(<span class="string">'update pagerank set score=%f where urlid=%d'</span> % (pr,urlid))</span><br><span class="line">      self.dbcommit()</span><br></pre></td></tr></table></figure><p></p><p>我们来运行该函数:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">crawler = crawler(<span class="string">'searchindex.db'</span>)</span><br><span class="line">crawler.calculatepagerank()</span><br></pre></td></tr></table></figure><p></p><p>如果我们想知道示例数据集中的哪个网页PageRank值最高，可以直接查询数据库。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cur = crawler.con.execute(<span class="string">'select * from pagerank order by score desc'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">  print(cur.next())</span><br><span class="line"><span class="comment"># 打印值为：</span></span><br><span class="line"><span class="comment">#(438, 2.5285160000000002)</span></span><br><span class="line"><span class="comment">#(2, 1.1614640000000001)</span></span><br><span class="line"><span class="comment">#(543, 1.064252)</span></span><br><span class="line">crawler.geturlname(<span class="number">438</span>)</span><br><span class="line"><span class="comment">#u'http://kiwitobes.com/wiki/Main_Page.html'</span></span><br></pre></td></tr></table></figure><p></p><p>从上述结果可以得知，“Main page”是分值是最高的，这也很正常，因为Wikipedia中的每一个网页都链接到该页面。<br>既然我们已经得到了每个网页的PageRank评分，那么我们应该将其加入评价函数中。<br>我们先写一个函数从数据库取出PageRank评分，并做归一化处理：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">pagerankscore</span><span class="params">(self,rows)</span>:</span></span><br><span class="line">  pageranks=dict( [row[<span class="number">0</span>],self.con.execute(<span class="string">'select score from pagerank where urlid=%d'</span> % row[<span class="number">0</span>]).fetchone()[<span class="number">0</span>] \</span><br><span class="line">  <span class="keyword">for</span> row <span class="keyword">in</span> rows]  )</span><br><span class="line">  maxrank=max(pageranks.values())</span><br><span class="line">  normalizedscores = dict( [(url,float(score)/maxrank) <span class="keyword">for</span> (url,score) <span class="keyword">in</span> pageranks.items() ] )</span><br></pre></td></tr></table></figure><p></p><p>再次修改weights表，将PageRank算法加入其中：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weights=[(<span class="number">1.0</span>,self.locationscore(rows)),(<span class="number">1.0</span>,self.frequencyscore(rows)),(<span class="number">1.0</span>,self.pagerankscore(rows))]</span><br></pre></td></tr></table></figure><p></p><p>现在搜索结果不仅考虑了PageRank评分，还考虑了网页内容的评分，现在我们搜索”Functional Programming”，发现搜索结果的排列结果显得更加合理了。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2.318146</span> http://kiwitobes.com/wiki/Functional_programming.html</span><br><span class="line"><span class="number">1.074506</span> http://kiwitobes.com/wiki/Programming_language.html</span><br><span class="line"><span class="number">0.517633</span> http://kiwitobes.com/wiki/Categorical_list_of_programming_languages.html <span class="number">0.439568</span> http://kiwitobes.com/wiki/Programming_paradigm.html</span><br><span class="line"><span class="number">0.426817</span> http://kiwitobes.com/wiki/Lisp_programming_language.html</span><br></pre></td></tr></table></figure><p></p><h3 id="利用衔接文本信息"><a href="#利用衔接文本信息" class="headerlink" title="利用衔接文本信息"></a>利用衔接文本信息</h3><p>在这一小节开始之前，我们看一个例子：<br></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;a href="www.google.com"&gt;best search engine&lt;/a&gt;</span><br></pre></td></tr></table></figure><p></p><p>上述的代表表示一个指向www.google.com的链接，链接的描述文字为“best search engine”，如果你写过网页，你会知道写链接的时候我们会给链接网址一个解释其内容的简短描述。所以，衔接文本上的信息会比较有价值，我们要利用这一信息，改善对搜索结果的排序。<br>对于一个目标网页，我们要参照所有其他网页对该网页的简短描述信息，来为目标网站打分。<br>我们按步骤来进行该过程：</p><ol><li>找到所有引用了目标网站的‘其他页面’。</li><li>查看‘其他页面’对目标网站的简短描述。</li><li>将用户的查询条件视为’用户描述’ 与 第二步中得到的‘其他网页’对目标页面的简短描述做对比，如果‘其他页面’的简短描述中包含用户描述的单词，那么就将‘简介单词中包含用户输入查询词’的引用目标的页面的PageRank评分，作为对该网页的评分。<br>一个目标页面可能被多个网站链接并描述，故我们需要将符合条件的网页的PageRank评分累加起来,作为目标页面的评分。</li></ol><p>我们也可以换一个流程，效果是一样的：</p><ol><li>根据查询词，找到链接表中含有查询词的所有链接。因为使用查询词做搜索条件，所以这些链接的描述与查询词一致。</li><li>如果第一步得到的链接中，链接到了搜索结果中的数据项，说明这个链接的引用页描述与用户描述一致，应该加分。</li><li>如果第一步中有多个链接，映射到搜索结果中的同一个数据项，则评分应该累加。<br>我们的程序就是按照上述的流程写的。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># rows为搜索结果,wordids是用户输入的查询词</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linktextscore</span><span class="params">(self,rows,wordids)</span>:</span></span><br><span class="line">  linkscores=dict([(rows[<span class="number">0</span>],<span class="number">0</span>)<span class="keyword">for</span> row <span class="keyword">in</span> rows]) <span class="comment"># rows每一项格式为:url 第一个单词的位置 第二个单词的位置...</span></span><br><span class="line">  <span class="keyword">for</span> wordid <span class="keyword">in</span> wordids:</span><br><span class="line">    <span class="comment"># 查看查询词中有哪些链接,得到'其他页面',而rows的第一列都是搜索结果页面，即'目标页面'</span></span><br><span class="line">    cur = self.con.execute(<span class="string">'select link.fromid,link.toid from linkwords,\</span></span><br><span class="line"><span class="string">    link where wordid=%d and linkwords.linkid=link.rowid'</span> %wordid)</span><br><span class="line">    <span class="keyword">for</span> (fromid,toid) <span class="keyword">in</span> cur:</span><br><span class="line">      <span class="keyword">if</span> toid <span class="keyword">in</span> linksscore:<span class="comment">#查询词得到的‘其他页面’，涵盖了搜索结果中的目标页面</span></span><br><span class="line">        <span class="comment">#得到pagerank，计算累加和</span></span><br><span class="line">        pr=self.con.execute(<span class="string">'select score from pagerank where urlid=%d'</span> % fromid).fetchone()[<span class="number">0</span>]</span><br><span class="line">        linkscores[toid]+=pr</span><br><span class="line">    maxscore=max(linkscores.values())</span><br><span class="line">    normalizedscores=dict( [(url,float(score)/maxscore <span class="keyword">for</span> (url,score) <span class="keyword">in</span> linkscores.items() ] )</span><br><span class="line">    <span class="keyword">return</span> normalizedscores</span><br></pre></td></tr></table></figure></li></ol><p>如果一个页面，没有被其他页面描述过，或者用户的描述与‘引用过该目标页面’的网页的描述不相符，那么这种度量方法，会得到该页面的评分为0的结果。<br>为了能够利用链接文本改善搜索结果的排名，我们需要修改weights表。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(<span class="number">1.0</span>,self.linktextscore(rows,wordids))</span><br></pre></td></tr></table></figure><p></p><p>这些度量之间，并不存在一组标准的权重，即使是大型的搜索引擎，也会时常改变他们对搜索结果的排名方法。<br>每种度量方法应该赋予多大的权重，取决于我们要创建的应用。</p><h2 id="利用神经网络学习数据之间的关联"><a href="#利用神经网络学习数据之间的关联" class="headerlink" title="利用神经网络学习数据之间的关联"></a>利用神经网络学习数据之间的关联</h2></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>如果您觉得读完本文有收获，不妨小额赞助我一下，让我有动力继续写出高质量的教程！</div><button id="rewardButton" disable="enable"><span>打赏</span></button><div id="QR" style="display:block"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/smacker.jpg" alt="倔强的土豆 微信支付"><p>微信支付</p></div></div></div></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2017/11/12/cluster/" rel="next" title="发现群组"><i class="fa fa-chevron-left"></i> 发现群组</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></div></article><div class="post-spread"></div></div></div><div class="comments" id="comments"><div id="gitment-container"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div id="sidebar-dimmer"></div><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">倔强的土豆</p><p class="site-description motion-element" itemprop="description">分享机器学习、深度学习的点滴</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">5</span> <span class="site-state-item-name">日志</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/laiqun" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:laiqun@msn.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#搜索引擎的定义与组成"><span class="nav-number">1.</span> <span class="nav-text">搜索引擎的定义与组成</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#建立搜索引擎的步骤"><span class="nav-number">2.</span> <span class="nav-text">建立搜索引擎的步骤</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据处理"><span class="nav-number">2.1.</span> <span class="nav-text">数据处理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据检索"><span class="nav-number">2.2.</span> <span class="nav-text">数据检索</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#抓取数据"><span class="nav-number">3.</span> <span class="nav-text">抓取数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#使用urllib来下载网页"><span class="nav-number">3.1.</span> <span class="nav-text">使用urllib来下载网页</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#书写爬虫"><span class="nav-number">3.2.</span> <span class="nav-text">书写爬虫</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#建立索引"><span class="nav-number">4.</span> <span class="nav-text">建立索引</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#设计数据库中的数据表"><span class="nav-number">4.1.</span> <span class="nav-text">设计数据库中的数据表</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#在网页中查找单词"><span class="nav-number">4.2.</span> <span class="nav-text">在网页中查找单词</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#加入索引"><span class="nav-number">4.3.</span> <span class="nav-text">加入索引</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#将普通文本加入索引"><span class="nav-number">4.3.1.</span> <span class="nav-text">将普通文本加入索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将链接处的文本加入索引"><span class="nav-number">4.3.2.</span> <span class="nav-text">将链接处的文本加入索引</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#测试加入索引功能"><span class="nav-number">4.3.3.</span> <span class="nav-text">测试加入索引功能</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#查询"><span class="nav-number">5.</span> <span class="nav-text">查询</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基于内容的排名"><span class="nav-number">5.1.</span> <span class="nav-text">基于内容的排名</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#归一化的方法"><span class="nav-number">5.1.1.</span> <span class="nav-text">归一化的方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单词频度"><span class="nav-number">5.1.2.</span> <span class="nav-text">单词频度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单词位置"><span class="nav-number">5.1.3.</span> <span class="nav-text">单词位置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单词距离"><span class="nav-number">5.1.4.</span> <span class="nav-text">单词距离</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#基于外部回指链接的排名"><span class="nav-number">5.2.</span> <span class="nav-text">基于外部回指链接的排名</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#数量上–简单计数"><span class="nav-number">5.2.1.</span> <span class="nav-text">数量上–简单计数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#质量上–pagerank算法"><span class="nav-number">5.2.2.</span> <span class="nav-text">质量上–pagerank算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#利用衔接文本信息"><span class="nav-number">5.2.3.</span> <span class="nav-text">利用衔接文本信息</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#利用神经网络学习数据之间的关联"><span class="nav-number">5.3.</span> <span class="nav-text">利用神经网络学习数据之间的关联</span></a></li></ol></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2017</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">倔强的土豆</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script><link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css"><script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script><script type="text/javascript">function renderGitment(){var a=new Gitmint({id:window.location.pathname,owner:"laiqun",repo:"laiqun.github.io",lang:navigator.language||navigator.systemLanguage||navigator.userLanguage,oauth:{client_secret:"55aaeb736714431ea52109dd66461b1644ca6177",client_id:"c90dfa80285ea91b9120"}});a.render("gitment-container")}renderGitment()</script></body></html><!-- rebuild by neat -->