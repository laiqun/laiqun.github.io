<!-- build time:Tue Feb 27 2018 08:28:06 GMT+0800 (CST) --><!DOCTYPE html><html class="theme-next mist" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3"><link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222"><meta name="keywords" content="Hexo, NexT"><meta name="description" content="到目前为止，我们已经考察过了一部分分类器，其中大多数都非常适合对未知数据的所属分类进行预测。但是，在利用多种不同的属性（比如价格、大小）对数值型数据进行预测时，贝叶斯分类器、决策树、以及支持向量机都不是最佳的算法。本章我们将对一系列的算法进行考查：这些算法可以接受训练，根据之前见过的样本数据做出数值类的预测。而且它们还"><meta property="og:type" content="article"><meta property="og:title" content="构建价格模型"><meta property="og:url" content="laiqun.github.io/2018/02/23/buildingPriceModels/index.html"><meta property="og:site_name" content="广阔天地，大有作为"><meta property="og:description" content="到目前为止，我们已经考察过了一部分分类器，其中大多数都非常适合对未知数据的所属分类进行预测。但是，在利用多种不同的属性（比如价格、大小）对数值型数据进行预测时，贝叶斯分类器、决策树、以及支持向量机都不是最佳的算法。本章我们将对一系列的算法进行考查：这些算法可以接受训练，根据之前见过的样本数据做出数值类的预测。而且它们还可以显示出预测的概率分布情况，以帮助用户对预测过程加以解释。在本章中，我们将考察"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="/2018/02/23/buildingPriceModels/few.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/more.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/inverse.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/subtract.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/gaussian.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/diff.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/scale1.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/scale1.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/sample.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/cumulative.jpg"><meta property="og:image" content="/2018/02/23/buildingPriceModels/density.jpg"><meta property="og:updated_time" content="2018-02-26T14:35:57.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="构建价格模型"><meta name="twitter:description" content="到目前为止，我们已经考察过了一部分分类器，其中大多数都非常适合对未知数据的所属分类进行预测。但是，在利用多种不同的属性（比如价格、大小）对数值型数据进行预测时，贝叶斯分类器、决策树、以及支持向量机都不是最佳的算法。本章我们将对一系列的算法进行考查：这些算法可以接受训练，根据之前见过的样本数据做出数值类的预测。而且它们还可以显示出预测的概率分布情况，以帮助用户对预测过程加以解释。在本章中，我们将考察"><meta name="twitter:image" content="/2018/02/23/buildingPriceModels/few.jpg"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",version:"5.1.3",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!0},fancybox:!0,tabs:!0,motion:{enable:!1,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="laiqun.github.io/2018/02/23/buildingPriceModels/"><title>构建价格模型 | 广阔天地，大有作为</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">广阔天地，大有作为</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">你看到我的筋斗云了嘛？</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="laiqun.github.io/2018/02/23/buildingPriceModels/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="倔强的土豆"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="广阔天地，大有作为"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">构建价格模型</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-23T22:07:14+08:00">2018-02-23 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/02/23/buildingPriceModels/#comments" itemprop="discussionUrl"><span class="post-comments-count gitment-comments-count" data-xid="/2018/02/23/buildingPriceModels/" itemprop="commentsCount"></span></a></span></div></header><div class="post-body" itemprop="articleBody"><p>到目前为止，我们已经考察过了一部分分类器，其中大多数都非常适合对未知数据的所属<strong>分类</strong>进行预测。但是，在利用多种不同的属性（比如价格、大小）对<strong>数值型数据</strong>进行预测时，贝叶斯分类器、决策树、以及支持向量机都不是最佳的算法。本章我们将对一系列的算法进行考查：这些算法可以接受训练，根据之前见过的样本数据做出<strong>数值类</strong>的预测。而且它们还可以显示出预测的概率分布情况，以帮助用户对预测过程加以解释。<br>在本章中，我们将考察如何利用这些算法来构造价格预测模型。经济学家认为，价格（尤其是拍卖价格）是一种利用集体智慧来决定商品真实价值的非常好的方法；在一个拥有众多买家和卖家的大型市场中，通常对于交易双方而言，商品的价格最终将会达到一个最优值。与此同时，对价格进行预测也是测试此类算法的一种很好的手段，因此在确定价格时，通常有许多不同的因素需要考虑。例如,当我们打算竞价拍卖一台笔记本电脑时，需要考虑处理器的速度、RAM容量、硬盘大小、屏幕分辨率、以及其它许多因素。<br>进行数值型预测的一项关键工作是确定哪些变量是重要的，以及如何将它们组合在一起。<br>在笔记本电脑的例子中，可能有一些变量即使对价格会产生一定的影响，其影响也几乎是微乎其微的，例如，赠送品、捆绑销售的软件。而且与硬盘大小相比，屏幕尺寸对最终价格所产生的影响可能更大一些。我们可以利用前面介绍的优化技术，自动确定各个变量的最佳权重。</p><h1 id="构造一个样本数据集"><a href="#构造一个样本数据集" class="headerlink" title="构造一个样本数据集"></a>构造一个样本数据集</h1><p>一个极富挑战的测验数值型预测算法的数据集应该具备某些特征，这些特征的存在会使得算法难以对数据做出预测。举例来说，如果你正打算购买电视机，那么很容易得到尺寸越大越好的结论，而这样的问题利用传统的统计技术来解决会更容易一些。因此，我们去考察那些价格并非简单的按照商品尺寸或特征数量的增长而价格成比例增长的数据集，这会更有挑战性。<br>在本节中，我们将根据一个假设的简单模型来构造一个有关葡萄酒价格的数据集。酒的价格是由酒的等级和储藏的年代共同决定的。该模型假设葡萄酒有“峰值年(peak age)”的现象，即相对于峰值年而言，年代稍早的品质会好一些，但品质不如峰值年；年代晚于峰值年的品质会急剧下降。一瓶高等级的葡萄酒从高价位开始，价格逐渐升高直到“峰值年”；而一瓶低等级的葡萄酒则会从一个低价开始，价格一路走低，即峰值年为生产出该酒的年。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> random <span class="keyword">import</span> random,randint</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wineprice</span><span class="params">(rating,age)</span>:</span></span><br><span class="line">    peak_age = rating<span class="number">-50</span> <span class="comment">#峰值年与酒的品质有关</span></span><br><span class="line">    <span class="comment"># 根据等级和年代来计算价格</span></span><br><span class="line">    price = rating/<span class="number">2</span></span><br><span class="line">    <span class="keyword">if</span> age &gt; peak_age:</span><br><span class="line">        <span class="comment"># 经过‘峰值年’，后继5年里其品质将会变差</span></span><br><span class="line">        price = price*(<span class="number">5</span>-(age-peak_age))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 价格在接近‘峰值年’时，价格为增加到原值的5倍</span></span><br><span class="line">        price = price*(<span class="number">5</span>*((age+<span class="number">1</span>)/peak_age))</span><br><span class="line">    <span class="keyword">if</span> price &lt;<span class="number">0</span>:</span><br><span class="line">        price =<span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> price</span><br></pre></td></tr></table></figure><p></p><p>我们还需要一个函数来批量生产数据集。下列函数生产了300瓶葡萄酒，根据模型求出这些葡萄酒的价格，然后在原有价格的基础上随机的加减了20%，以此来表现诸如税收和价格局部变动的情况，这同时也是为了增加数值预测的难度。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">winset1</span><span class="params">()</span>:</span></span><br><span class="line">    rows = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">300</span>):</span><br><span class="line">        <span class="comment">#随机生成年代和等级</span></span><br><span class="line">        rating = random()*<span class="number">50</span>+<span class="number">50</span></span><br><span class="line">        age = random()*<span class="number">50</span></span><br><span class="line">        <span class="comment">#得到一个参考价格</span></span><br><span class="line">        price = wineprice(rating,age)</span><br><span class="line">        <span class="comment">#增加“噪声”</span></span><br><span class="line">        price*=(random()*<span class="number">0.4</span>+<span class="number">0.8</span>)</span><br><span class="line">        <span class="comment">#加入数据集</span></span><br><span class="line">        rows.append(&#123;<span class="string">'input'</span>:(rating,age),<span class="string">'result'</span>:price)</span><br><span class="line">    <span class="keyword">return</span> rows</span><br></pre></td></tr></table></figure><p></p><p>我们来测试一下前面编写的两个函数:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">wineprice(<span class="number">95.0</span>,<span class="number">3.0</span>)<span class="comment">#品质为95，储藏了3年</span></span><br><span class="line"><span class="comment">#21.111</span></span><br><span class="line">wineprice(<span class="number">95.0</span>,<span class="number">8.0</span>)<span class="comment">#品质为95，储藏了8年</span></span><br><span class="line"><span class="comment">#47.5</span></span><br><span class="line">winprice(<span class="number">99.0</span>,<span class="number">1.0</span>)<span class="comment">#品质为99,储藏了1年</span></span><br><span class="line"><span class="comment">#10.10</span></span><br><span class="line">data = wineset1()</span><br><span class="line"><span class="comment">#data[0]为&#123;'input':&#123;63.6,21.5&#125;,'result':34.5&#125;</span></span><br><span class="line"><span class="comment">#data[1]为&#123;'input':&#123;74.9,48.0&#125;,'result':0.0&#125; </span></span><br><span class="line"><span class="comment">#data[1]储藏时间太久，过期了</span></span><br></pre></td></tr></table></figure><p></p><p>变量的相互作用，使得这一个数据集很适合与对算法的测试。</p><h1 id="k-近邻算法"><a href="#k-近邻算法" class="headerlink" title="k-近邻算法"></a>k-近邻算法</h1><p>对于我们的葡萄酒定价问题而言，最简单的做法与人们人们尝试手动进行定价时所采用的做法是一样的——即，找到几瓶情况最为相似的酒，并假设其价格大体相同。算法通过寻找与当前所关注的商品情况相似的一组商品，对这些商品的价格求均值，进而做出价格预测。这种方法被称为k-最近邻算法(k-nearest neighbors,kNN)。</p><h2 id="近邻数的选择"><a href="#近邻数的选择" class="headerlink" title="近邻数的选择"></a>近邻数的选择</h2><p>kNN 中k代表的，是为了求得最终结果而参与求平均运算的商品数量。对于理想情况下的数据集，我们可以令k=1，这意味着我们仅仅考虑距离最近的邻居作为参考，并将其价格视为最终答案。不过在现实世界中，总是没有那样理想化。在本例中，我们故意引入了“<strong>噪声</strong>”，来模拟这样的情况（随机的加减了20%）。由于有了这些噪声，一部分顾客可能会因此大赚一笔；而也有消息闭塞的客户，可能会为此支付更多的钱。基于这样的原因，我们最好多<strong>选取一些近邻</strong>，然后对他们<strong>取平均，以此来减少噪声</strong>。</p><h3 id="近邻数过少"><a href="#近邻数过少" class="headerlink" title="近邻数过少"></a>近邻数过少</h3><p>为了形象的说明选择过少近邻的问题，我们以存储时间为例来考虑一下只有一个描述性变量的情况。下图是一副反映价格(y轴)和存储时间(x轴)之间的关系的图。图上还标注了当只使用一个最近邻时所得到的曲线。<br><img src="/2018/02/23/buildingPriceModels/few.jpg" title="k过小-选择的近邻数过少"><br>请注意次数所预测的价格是怎样过度依赖于曲线的随机变化的。如果我们打算利用图中的曲线进行预测，那么当我们真的只关注一瓶15年的葡萄酒和一瓶16年的葡萄酒价格上的差异时，我们就会得出结论，认为这两瓶葡萄酒在价格上会存在一个大的跳跃。</p><h3 id="近邻数过多"><a href="#近邻数过多" class="headerlink" title="近邻数过多"></a>近邻数过多</h3><p>选择过多的近邻同样会降低准确性，因为算法会对那些<strong>与被查询的商品根本没有任何相似性的商品求平均</strong>。下图为取20个近邻求平均后得到的曲线。<br><img src="/2018/02/23/buildingPriceModels/more.jpg" title="k过大-选择的近邻数过多"><br>很显然，对太多的葡萄酒价格取平均，就会极大地低估25年左右的葡萄酒对预估的价格造成的影响。<br>为了选择合适的近邻数，我们可以针对不同的数据集加以手工选择，或者采用一些优化措施。</p><h2 id="定义相似度的度量方法"><a href="#定义相似度的度量方法" class="headerlink" title="定义相似度的度量方法"></a>定义相似度的度量方法</h2><p>对于kNN算法，我们首先要做的一件事情是，寻找一种衡量两件物品之间相似度的方法。<br>我们已经在本书中学到了各种不同的度量方法。此处，我们将选用欧几里得距离作为度量算法。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">euclidean</span><span class="params">(v1,v2)</span>:</span></span><br><span class="line">    d=<span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(v1)):</span><br><span class="line">        d+=(v1[i]-v2[i])**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> math.sqrt(d)</span><br></pre></td></tr></table></figure><p></p><p>我们来测试一下这个函数:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#data[0]['input']=&#123;82.7,49.2&#125;</span></span><br><span class="line"><span class="comment">#data[1]['input']=&#123;98.9,25.7&#125;</span></span><br><span class="line">euclidean(data[<span class="number">0</span>][<span class="string">'input'</span>],data[<span class="number">1</span>][<span class="string">'input'</span>])</span><br><span class="line"><span class="comment">#28.5</span></span><br></pre></td></tr></table></figure><p></p><p>你会注意到，该函数在计算距离时，对年代和品质是<strong>同等对待</strong>的，但现实的情况是，某些变量对最终价格所产生的影响往往会比其他变量更大。这是kNN众所周知的一个缺点，而解决这一问题的方法会在后续部分<strong>处理不同类型的变量</strong>中。</p><h2 id="k最近邻算法的代码"><a href="#k最近邻算法的代码" class="headerlink" title="k最近邻算法的代码"></a>k最近邻算法的代码</h2><p>kNN是一种实现起来相对简单的算法，虽然这种算法的计算量很大，其优点在于其没有<strong>训练</strong>的过程，即有新数据加入数据集时，不需要训练。<br>我们来编写一个函数，利用该函数来计算给定商品与数据集中的所有商品之间的距离：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getdistances</span><span class="params">(data,vec1)</span>:</span><span class="comment"># vec1为给定商品,data为数据集</span></span><br><span class="line">    distancelist=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(data)):</span><br><span class="line">        vec2= data[i][<span class="string">'input'</span>]<span class="comment">#从数据集中取出一项，命名为vec2</span></span><br><span class="line">        distacelist.append((euclidean(vec2,vec1),i))</span><br><span class="line">    distancelist.sort()</span><br><span class="line">    <span class="keyword">return</span> distancelist</span><br></pre></td></tr></table></figure><p></p><p>该函数针对指定向量，与数据集中的任何一个向量计算距离，并将结果放到了一个大列表中。为了让距离最近者位于最前端，我们对列表进行了排序。<br>kNN函数利用了上述距离列表，并对其中的前k项求平均值。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knnestimate</span><span class="params">(data,vec1,k=<span class="number">5</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 得到经过排序的距离值</span></span><br><span class="line">    dlist = getdistances(data,vec1)</span><br><span class="line">    avg = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 对前k项结果求平均</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        index = dlist[i][<span class="number">1</span>]</span><br><span class="line">        avg+=data[index][<span class="string">'result'</span>]</span><br><span class="line">    avg=avg/k</span><br><span class="line">    <span class="keyword">return</span> avg</span><br></pre></td></tr></table></figure><p></p><p>现在我们队新商品进行估价来测试一下上述函数:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">knnestimate(data,(<span class="number">95.0</span>,<span class="number">3.0</span>))</span><br><span class="line"><span class="comment">#29.17</span></span><br><span class="line">knnestimate(data,(<span class="number">99.0</span>,<span class="number">3.0</span>))</span><br><span class="line"><span class="comment">#22.35</span></span><br><span class="line">knnestimate(data,(<span class="number">99.0</span>,<span class="number">5.0</span>))</span><br><span class="line"><span class="comment">#37.6</span></span><br><span class="line">wineprice(data,(<span class="number">99.0</span>,<span class="number">5.0</span>))<span class="comment">#得到实际价格,注意与上述预测的价格做比较</span></span><br><span class="line"><span class="comment">#30.30 </span></span><br><span class="line">knnestimate(data,(<span class="number">99.0</span>,<span class="number">5.0</span>),k=<span class="number">1</span>)<span class="comment">#尝试使用更少的近邻</span></span><br><span class="line"><span class="comment"># 38.07</span></span><br></pre></td></tr></table></figure><p></p><p>请尝试不同的输入参数和不同的k值，看一看它们对结果产生的影响。</p><h2 id="加权kNN"><a href="#加权kNN" class="headerlink" title="加权kNN"></a>加权kNN</h2><p>目前我们所使用的算法有可能会选择距离过远的近邻，对于这样的情况，一种补偿的办法是根据距离的远近来确定每个近邻的权重。这种思想与前面所讲述的推荐算法相同，在那里我们计算一个寻求推荐的用户与其他人在偏好上的相似程度，并将相似程度作为了权重。与你相似的人权重会多一些，与你相似度较低的人，权重会少一些。</p><h3 id="为近邻分配权重"><a href="#为近邻分配权重" class="headerlink" title="为近邻分配权重"></a>为近邻分配权重</h3><p>商品越是相近，彼此间的距离就越小，我们需要一种方法来讲距离转换为权重。这里我们将介绍3种方法。<br><strong>1.倒数函数</strong><br>该函数最为简单的一种形式是返回距离的倒数。当完全一样或者非常接近的商品，会使得权重变得非常大，甚至无穷大。基于这一的原因，我们有必要在对距离求倒数的分子和分母上加上一个小小的常量。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">inverserweight</span><span class="params">(dist,num=<span class="number">1.0</span>,const=<span class="number">0.1</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> num/(dist+const)</span><br></pre></td></tr></table></figure><p></p><p>该函数执行速度快，也易于实现，我们还可以尝试一下不同的num值，看看怎样的值效果更好一些。<br>该方法的主要缺陷在于：它会为特别相似的近邻分配很大的权重，而稍远一点的近邻，其权重“衰减”的很快。这些情况也许正是我们所期望的，但有的时候，这也会是算法对噪声变得更加敏感。<br>以下为倒数函数的示意图：<br><img src="/2018/02/23/buildingPriceModels/inverse.jpg" title="倒数函数示意图"><br><strong>2.减法函数</strong><br>这是一个简单的函数，它用一个常量值减去距离。如果相减的结果大于0，则权重为相减的结果；否则为0。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">substractweight</span><span class="params">(dist,const=<span class="number">1.0</span>)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> dist&gt;const:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> const-dist</span><br></pre></td></tr></table></figure><p></p><p>该函数客户了前述对特别相似的近邻项分配过大权重的问题，但是它也有自身的局限。<br>由于权重值最终会跌至0，因此我们有可能找不到距离足够近的项，将其视为近邻，对于某些待预测的数据，可能会出现找不到“足够近似”的项而预测结果为0的情况。<br>以下为减法函数的示意图：<br><img src="/2018/02/23/buildingPriceModels/subtract.jpg" title="减法函数示意图"><br><strong>3.高斯函数</strong><br>我们来看一下高斯函数，有时候也叫它“钟型曲线”。该方法比前面提到的函数要复杂一些，不过该方法克服了前述函数的局限。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gaussian</span><span class="params">(dist,sigma=<span class="number">10.0</span>)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> math.e**(-dist**<span class="number">2</span>/(<span class="number">2</span>*sigma**<span class="number">2</span>))</span><br></pre></td></tr></table></figure><p></p><p>该函数在距离为0时权重为1，并且权重值会随着距离的增加而减少。与减法函数不同的是，这里的权重值永远不会跌至0，因此该方法总是可以做出预测的。<br>以下为高斯函数的示意图：<br><img src="/2018/02/23/buildingPriceModels/gaussian.jpg" title="高斯函数示意图"></p><p>我们来测试前述的3种函数，传入不同的参数值，看一下这些方法彼此间的差异如何：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">subtractweight(<span class="number">0.1</span>)</span><br><span class="line"><span class="comment"># 0.9</span></span><br><span class="line">inverseweight(<span class="number">0.1</span>)</span><br><span class="line"><span class="comment"># 5.0</span></span><br><span class="line">gaussian(<span class="number">0.1</span>)</span><br><span class="line"><span class="comment"># 0.99501247919268232</span></span><br><span class="line">gaussian(<span class="number">1.0</span>)</span><br><span class="line"><span class="comment"># 0.60653065971263342</span></span><br><span class="line">subtractweight(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 0.0</span></span><br><span class="line">inverseweight(<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 0.90909090909090906</span></span><br><span class="line">gaussian(<span class="number">3.0</span>)</span><br><span class="line"><span class="comment"># 0.01110899653824231</span></span><br></pre></td></tr></table></figure><p></p><p>我们可以看到，所有的函数都是在距离为0处取得最大值，然后随着距离增加，其函数值越来越小。</p><h3 id="加权kNN的代码实现"><a href="#加权kNN的代码实现" class="headerlink" title="加权kNN的代码实现"></a>加权kNN的代码实现</h3><p>实现加权kNN算法的代码与普通的kNN函数在执行过程上是相似的，函数首先获得经过排序的距离值，选择距离最近的k个元素。<br>与普通的kNN算法不同的是，加权kNN函数算法的最重要的区别在于，它并不是对这些元素简单的求平均，它求的是加权平均。<br>加权平均的结果是通过将每一项的值乘上对应权重，然后将结果累加；求得总和后，我们再将其初上所有的权重值之和。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weightedknn</span><span class="params">(data,vec1,k=<span class="number">5</span>,weightf=gaussian)</span>:</span></span><br><span class="line">    <span class="comment"># 得到经过排序的距离值</span></span><br><span class="line">    dlist = getdistances(data,vec1)</span><br><span class="line">    avg = <span class="number">0.0</span></span><br><span class="line">    total_weight=<span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 对前k项结果求平均</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        index = dlist[i][<span class="number">1</span>]</span><br><span class="line">        dist = dlist[i][<span class="number">0</span>]</span><br><span class="line">        weight = weightf(dist)</span><br><span class="line">        avg+=data[index][<span class="string">'result'</span>]*weight</span><br><span class="line">        total_weight += weight</span><br><span class="line">    avg=avg/total_weight</span><br><span class="line">    <span class="keyword">return</span> avg</span><br></pre></td></tr></table></figure><p></p><p>上述函数循环遍历距离最近的k个近邻，并将各个距离值传入预先定义好的权重函数。变量avg的值是通过将权重乘上对应数据项的数值而求得的。变量total_weight是所有权重值的总和。最后，我们将avg除上总的权重和。<br>我们来测试一下这个函数:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">weightedknn(data,(<span class="number">99.0</span>,<span class="number">5.0</span>))</span><br><span class="line"><span class="comment"># 32.6</span></span><br></pre></td></tr></table></figure><p></p><p>在本例中，通过计算所得的结果我们可以看出，weightedknn比knnestmate更接近正确答案。不过，这只是针对两组样例而言的。更加严格的测验过程需要涉及数据集中大量的数据项，测试出最佳的函数与最佳的参数。这回在<strong>交叉验证</strong>小节进行讲述。</p><h2 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h2><p>交叉验证是将数据拆分成训练集和测试机的一些列技术的统称。我们将训练集传入算法，这些训练集伴随着正确的答案（此处为价格）被输入模型，这个过程叫“训练”；训练后，我们就得到了一组可以用来进行预测的模型。随后，我们要求算法对测试集中的每一项数据做出预测，将模型给出的答案与正确的答案进行比较。将测试集比较完后，我们便可以得到评估模型准确程度的统计结果。<br>通常交叉验证会进行若干次，每次对数据的拆分都不相同。典型的情况下，测试集只会包含小部分数据，大概是所有数据的5%，剩下的95%都被用来做训练集。我们来编写函数实现对数据集的拆分。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dividedata</span><span class="params">(data,test=<span class="number">0.05</span>)</span>:</span></span><br><span class="line">    trainset=[]</span><br><span class="line">    testset=[]</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">if</span> random()&lt;test:</span><br><span class="line">            testset.append(row)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            trainset.append(row)</span><br><span class="line">    <span class="keyword">return</span> trainset,testset</span><br></pre></td></tr></table></figure><p></p><p>我们还需要一个运行模型并统计模型预测与实际值误差的函数。我们要为测试集的每一项都调用算法，得到一个预测值，将这个预测值与实际值进行比较得到一个差值结果。我们需要将测试集中每一项的差值累加起来，以此来评估预测结果与正确结果在整体上的差距。<br>我们这里使用差值的平方来表示模型预测值与实际值的偏离程度。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">testalgorithm</span><span class="params">(algf,trainset,testset)</span>:</span></span><br><span class="line">    error = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> testset:</span><br><span class="line">        guess = algf(trainset,row[<span class="string">'input'</span>])</span><br><span class="line">        error += (row[<span class="string">'result'</span>]-guess)**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> error/len(testset)</span><br></pre></td></tr></table></figure><p></p><p>testalgotithm的algf接受一个算法函数作为参数，而该算法函数接受一个数据集和一个查询项作为参数。testalgorithm会循环遍历测试集中的每一行，并将algf的预测结果与实际结果相减后的平方视为误差。<br>对数字求<strong>平方</strong>法是一个常见的做法，因为它会凸显较大的误差，当误差较大时，平方后会使得误差显得更大。这意味着，一个在大多数时候都非常接近正确值，但偶尔存在较大偏离的算法，比起那些“始终都比较接近正确值的算法”要差一些。一般而言，这种情况是我们所期望的，不过也有例外，举例来说：如果一个算法在大多数情况下都非常接近正确值，偶尔犯一个大错误还是可以接受的情况，这时候我们将差的<strong>绝对值</strong>累加起来即可。</p><p>最后，我们需要一个函数来多次调用前述的拆分数据集函数与算法误差统计函数。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">crossvalidate</span><span class="params">(algf,data,trials=<span class="number">100</span>,test=<span class="number">0.05</span>)</span>:</span></span><br><span class="line">    error = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(trials):</span><br><span class="line">        trainset,testset = dividedata(data,test)</span><br><span class="line">        error +=testalgorithm(algf,trainset,testset)</span><br><span class="line">    <span class="keyword">return</span> error/trials</span><br></pre></td></tr></table></figure><p></p><p>尝试使用不同的参数来测试一下这个函数,比如不同的k值：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">crossvalidate(numpredict.knnestimate,data)<span class="comment"># k=5</span></span><br><span class="line"><span class="comment"># 254.06864176819553</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knn3</span><span class="params">(d,v)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> numpredict.knnestimate(d,v,k=<span class="number">3</span>) <span class="comment"># k=3</span></span><br><span class="line">crossvalidate(knn3,data)</span><br><span class="line"><span class="comment"># 166.97339783733005</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knn1</span><span class="params">(d,v)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> numpredict.knnestimate(d,v,k=<span class="number">1</span>) <span class="comment"># k=1 </span></span><br><span class="line">crossvalidate(knn1,data)</span><br><span class="line"><span class="comment"># 209.54500183486215</span></span><br></pre></td></tr></table></figure><p></p><p>正如前面讨论的那样，使用过多和过少的近邻都会导致效果不好。在本例中，k=3的效果要比k=5或k=1的效果好。<br>我们也可以测试一下不同的权重函数，看看前述讨论的3种权重函数哪一个效果好一些。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">crossvalidate(numpredict.weightedknn,data)<span class="comment">#使用高斯函数</span></span><br><span class="line"><span class="comment"># 200.34187674254176</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">knninverse</span><span class="params">(d,v)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> numpredict.weightedknn(d,v,weightf=inverseweight)<span class="comment">#使用倒数函数</span></span><br><span class="line">crossvalidate(knninverse,data)</span><br><span class="line"><span class="comment"># 148.85947702660616</span></span><br></pre></td></tr></table></figure><p></p><p>待我们正确设置好参数之后，权重kNN算法似乎能够针对上述训练集给出更好的结果。选择正确的参数也许会费一些时间，但是对于一个特定的训练集而言，这样的工作只需要做一次即可。随着训练集内容的增长，偶尔我们还需要对参数进行更新。后续的<strong>对缩放结果进行优化</strong>小节中，我们将考察自动确定部分参数的方法。</p><h2 id="处理不同属性"><a href="#处理不同属性" class="headerlink" title="处理不同属性"></a>处理不同属性</h2><h3 id="增加两个新属性——酒瓶容量与生产流水线编号"><a href="#增加两个新属性——酒瓶容量与生产流水线编号" class="headerlink" title="增加两个新属性——酒瓶容量与生产流水线编号"></a>增加两个新属性——酒瓶容量与生产流水线编号</h3><p>前文所述的数据集是特意做了简化的，用来预测价格的所有属性大致上是可以比较的，而且这些属性对最终价格而言都是有意义的。<br>现在我们可以引入一个与价格完全不相关的属性，生产葡萄酒时的流水线编号，那么这一个变量也会被纳入距离计算之中。如果这样，对于其他各个属性都是完全一样的，仅仅是生产流水线编号不一样，算法给出的价格也是不同的，这种情况会使得准确度大大降低。</p><p>因为所有的变量都位于同一值域范围内，因此利用这些变量算出的距离值是有意义的。现在，我们加入一个新的属性，比如酒瓶的容量，该属性以毫升为单位。与之间所述的其他属性不同（那些属性的值域范围为0-100），这个属性的值域范围可能达到1500。很明显，新加入的酒瓶容量属性对距离计算所产生的影响将更加显著，其影响超过任何其他属性对距离计算产生的影响。这意味着，在计算距离的过程中，其它属性产生的作用可能微乎其微。如下图所示：</p><img src="/2018/02/23/buildingPriceModels/diff.jpg" title="不同的属性对距离计算的影响"><p>上图中横轴为酒瓶容量，纵轴为储藏年数。<br>我们来修改前述的数据集生成代码，增加酒瓶容量和生成流水线编号。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wineset2</span><span class="params">()</span>:</span></span><br><span class="line">    rows = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">300</span>):</span><br><span class="line">        rating = random()*<span class="number">50</span>+<span class="number">50</span></span><br><span class="line">        age = random()*<span class="number">50</span></span><br><span class="line">        aisle = float(randint(<span class="number">1</span>,<span class="number">20</span>))<span class="comment">#新加</span></span><br><span class="line">        bottlesize = [<span class="number">375.0</span>,<span class="number">750.0</span>,<span class="number">1500.0</span>,<span class="number">3000.0</span>] <span class="comment">#新加，四种酒瓶容量，随机算一个</span></span><br><span class="line">        price = wineprice(rating,age)</span><br><span class="line">        price *= (bottlesize/<span class="number">750</span>)</span><br><span class="line">        price *= (randm()*<span class="number">0.9</span>+<span class="number">0.2</span>)</span><br><span class="line">        rows.append(&#123;<span class="string">'input'</span>:(rating,age,aisle,bottlesize),<span class="string">'result'</span>:price&#125;)</span><br><span class="line">    <span class="keyword">return</span> rows</span><br></pre></td></tr></table></figure><p></p><p>测试该函数产生的数据集在现有算法上的效果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">data = wineset2()</span><br><span class="line">crossvalidate(knn3,data)</span><br><span class="line"><span class="comment"># 1427</span></span><br><span class="line">crossvalidate(weightedknn,data)</span><br><span class="line"><span class="comment"># 1195</span></span><br></pre></td></tr></table></figure><p></p><p>我们会发现，即使数据集包含了更多的信息，而且噪声也更少了，理论上，这应该得到更好的预测结果；但实际上预测效果比之前的结果更糟糕。其原因在于，算法还不知道如何对不同的属性加以区别对待。</p><h3 id="将不同值域的属性缩放到同一值域"><a href="#将不同值域的属性缩放到同一值域" class="headerlink" title="将不同值域的属性缩放到同一值域"></a>将不同值域的属性缩放到同一值域</h3><p>此处，我们不是需要一种根据属性的值来计算距离的方法，而是需要一种对数值进行<strong>归一化</strong>处理的方法，从而使所有属性都位于相同的值域范围内。做这样做也有利于查找那些不必要的属性（生成流水线编号），或者至少能降低其对距离计算的影响。一种可行的办法就是在进行任何计算之间先对数据按比例进行缩放。<br>按比例对数据进行缩放的简单形式是每个维度上的数值乘上该一个常量，如下图所示：<br><img src="/2018/02/23/buildingPriceModels/scale1.jpg" title="酒瓶容量的属性乘上(1/10)"><br>上图横轴为酒瓶容量，纵轴为储藏年数。我们可以看到，酒瓶容量被值为(1/10)的比例因子缩小了，相应的，近邻的距离计算值也会发生变化。这种做法解决了一些属性天生比其他属性更加<strong>强势</strong>问题。<br>那对于重要程度不高的属性，应该如何处置呢？ 如果我们将其乘上比例因子0，会发生怎样的变化呢，如下图所示：<br><img src="/2018/02/23/buildingPriceModels/scale1.jpg" title="通道容量属性乘上(0)"><br>上图横轴为生产流水线编号，纵轴为储藏年数。<br>我们可以发现进行距离计算时，生成流水线编号这个属性完全被忽略了，只按照存储年数来计算距离。如果所有无关紧要的变量都被缩放到了0，那么算法将会更加准确。<br>我们来编写一个函数，传入数据集和每个属性的缩放程度列表，该函数对不同的属性按照相应的缩放比例因子进行缩放。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用实例 rescale(data,[10,10,0,0.5]) </span></span><br><span class="line"><span class="comment"># [10,10,0,0.5] 分别是评级、年代、通道号、酒瓶容量的缩放比例</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rescale</span><span class="params">(data,scale)</span>:</span></span><br><span class="line">    scaleddata=[]</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> data:</span><br><span class="line">        scaled=[scale(i)*row[<span class="string">'input'</span>][i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(scale))]</span><br><span class="line">        scaleddata.append(&#123;<span class="string">'input'</span>:scaled,<span class="string">'result'</span>:row[<span class="string">'result'</span>]&#125;)</span><br><span class="line">    <span class="keyword">return</span> scaleddata</span><br></pre></td></tr></table></figure><p></p><p>我们精心挑选了一组缩放比例因子，对数据集进行按比例缩放，看看是否能得到满意的预测效果。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sdata=rescale(data,[<span class="number">10</span>,<span class="number">10</span>,<span class="number">0</span>,<span class="number">0.5</span>])</span><br><span class="line">crossvalidate(knn3,sdata)</span><br><span class="line"><span class="comment"># 660.9964024835578</span></span><br><span class="line">crossvalidate(numpredict.weightedknn,sdata)</span><br><span class="line"><span class="comment"># 852.32254222973802</span></span><br></pre></td></tr></table></figure><p></p><p>对于上述少量样例数据而言，这样的结果比之前的效果好，我们可以尝试修改一下scale列表中的参数值，看看能否取得更好的结果。</p><h3 id="对缩放因子进行优化"><a href="#对缩放因子进行优化" class="headerlink" title="对缩放因子进行优化"></a>对缩放因子进行优化</h3><p>这里我们考察自动确定缩放因子的方法，在这里的例子中，要选择一个合适的参数进行缩放并不困难，因为我们已经事先知道了每个属性的重要程度。但是，大多数情况下所面对的数据集都不会是自己构造的，而且我们未必会知道每个变量的重要程度。<br>理论上，我们可以尝试大量不同数值的组合，知道发现一个足够好的结果为止，不过要进行数以百计的测试和考察，这个工作也非常乏味。所幸的是，如果你有前面介绍的优化算法的话，你可以让计算机自动的寻找最优解。<br>优化算法只需要提供变量的个数以及每个变量的定义域还有成本函数即可。<br><strong>确定成本函数</strong>：<br>由于函数corssvalidate对于较差的题解，会返回一个较高的数值结果，因此它是一个天然的成本函数。我们唯一要做的，就是把它封装一下，它将接收可能的题解，此处的题解为不同属性对应的缩放因子。并对题解进行评价：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createcostfunction</span><span class="params">(algf,data)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">costf</span><span class="params">(scale)</span>:</span></span><br><span class="line">        sdata = rescale(data,scale)</span><br><span class="line">        <span class="keyword">return</span> crossvalidate(algf,sdata,trials=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> costf</span><br></pre></td></tr></table></figure><p></p><p><strong>确定每个变量的定义域</strong>：<br>此处每个变量的含义为每一个属性的权重范围。由于负数权重只是对于正数权重的一个镜像，并且我们算的是两个属性的差值，故负数对距离的计算不会有影响。因此我们将定义域的最小值设置为0；定义域的最大值理论上多大都可以，但从实际应用出发，我们将其设置为20。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">weightdomain=[(<span class="number">0</span>,<span class="number">20</span>)]*<span class="number">4</span></span><br></pre></td></tr></table></figure><p></p><p>现在，我们已经准备好了优化算法所需要的仪器，现在开始尝试一下模拟退火优化算法：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">costf=createcostfunction(knnestimate,data)</span><br><span class="line">annealingoptimize(weightdomain,costf,step=<span class="number">2</span>)</span><br><span class="line"><span class="comment"># [11,18,0,6]</span></span><br></pre></td></tr></table></figure><p></p><p>结果非常好，算法不但明确“生产流水线编号”是一个没有价值的变量，并将其比例缩放到几乎为0；而且还对年代、品质、酒瓶容量属性做出了不同比例的放大。<br>我们可以尝试一下更慢但是更精确的遗传优化算法，它会返回一组类似的结果：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#geneticoptimize(weightdomain,costf,popsize=5,lrate=1,maxv=4,iters=20)</span></span><br><span class="line"><span class="comment"># [20,18,0,12]</span></span><br></pre></td></tr></table></figure><p></p><p>以这种方式对变量的缩放因子进行优化的一个好处在于，我们很快就能发觉哪些变量是重要的以及重要程度多大。有时候，有的数据不是很有价值，并且很难收集到，或者收集代价高昂，我们完全可以忽略这些数据避免额外的成本投入。在制定价格策略时，知道哪些变量是重要的，哪些是我们给商品定价的关键属性；另一方面，根据变量的重要程度，我们也可以知道如何将商品设计的与众不同，来取得更高的价格。</p><h2 id="不对称分布"><a href="#不对称分布" class="headerlink" title="不对称分布"></a>不对称分布</h2><p>前面我们假设对数据平均或者加权平均，就会得到一个“价格”的合理估计。在大多数情况下，这样是没问题的。但有些情况下，会存在一些无法测定的属性，它们会对结果产生很大的影响。<br>假设现在葡萄酒的销售渠道分为了2种，一种是酒馆中销售的；另外一种是折扣店销售的，顾客会得到50%的折扣。不幸的是，销售渠道这个信息并没有被记录在数据中。<br>我们来编写函数来构造这样一组数据集:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">wineset3</span><span class="params">()</span>:</span></span><br><span class="line">    rows = wineset1()</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">        <span class="keyword">if</span> random()&lt;<span class="number">0.5</span>:<span class="comment">#有一半的概率是从折扣店买到的</span></span><br><span class="line">            row[<span class="string">'result'</span>]*=<span class="number">0.5</span></span><br></pre></td></tr></table></figure><p></p><p>假如我们使用kNN或者加权kNN算法，对需要预测的葡萄酒的价格进行预估，会发现这样的情况：由于数据集中没有记录购买渠道信息，因此我们无法将这一情况考虑在内，进行近邻距离计算的时候也不会考虑这个因素。最终的结果是算法给出的平均值将同时设计两组销售方式，这就相当于大概有25%的折扣。我们来验证一下我们的想法：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data=wineset3( )</span><br><span class="line">wineprice(<span class="number">99.0</span>,<span class="number">20.0</span>)</span><br><span class="line"><span class="comment">#106.07142857142857</span></span><br><span class="line">weightedknn(data,[<span class="number">99.0</span>,<span class="number">20.0</span>])</span><br><span class="line"><span class="comment">#83.475441632209339</span></span><br><span class="line">crossvalidate(numpredict.weightedknn,data)</span><br><span class="line"><span class="comment">#599.51654107008562</span></span><br></pre></td></tr></table></figure><p></p><p>如果你只是想得到一个整体上的估计，这是一种可行的办法，但是它不能准确的反映某个个体实际购买的价格。为了能更加反映某个体的实际购买的价格情况，我们需要估计一瓶待估价的葡萄酒落在不同价格区间的概率。</p><h3 id="估计概率密度"><a href="#估计概率密度" class="headerlink" title="估计概率密度"></a>估计概率密度</h3><p>除了取得近邻的加权平均并得到一个价格预估值外，知道某葡萄酒落入指定价格区间的概率也有可能是一件非常值得关注的事情。举例来说：输入品质为99、储藏年数为20年，我们需要一个函数来告诉我们，它的价格介于40-80元的概率为50%，而价格介于80-100元的概率也是50%。<br>我们来编写这个函数，返回0-1之间的一个概率值。<br>具体做法是这样的：</p><ol><li>计算位于指定范围区间内的近邻权重值之和，记为nweight</li><li>计算所有近邻的权重值之和，即为tweight</li><li>函数返回nweight/tweight，这个值即表示预测价格落入该区间的概率</li></ol><p>我们来编写该计算流程:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probguess</span><span class="params">(data,vec1,low,high,k=<span class="number">5</span>,weightf=gaussian)</span>:</span></span><br><span class="line">    dlist = getdistances(data,vec1)</span><br><span class="line">    nweight = <span class="number">0.0</span></span><br><span class="line">    tweight = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(k):</span><br><span class="line">        dlist = dlist[i][<span class="number">0</span>]</span><br><span class="line">        index = dlist[i][<span class="number">1</span>]</span><br><span class="line">        weight = weightf(dist)</span><br><span class="line">        v = data[index][<span class="string">'result'</span>]</span><br><span class="line">        <span class="comment">#如果该近邻点落入指定的价格区间</span></span><br><span class="line">        <span class="keyword">if</span> v&gt;=low <span class="keyword">and</span> v&lt;=high:</span><br><span class="line">            nweight+=weight</span><br><span class="line">        tweight+=weight</span><br><span class="line">        <span class="keyword">if</span> tweight==<span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment">#概率等于指定范围区间的权重和除上所有的近邻权重和</span></span><br><span class="line">        <span class="keyword">return</span> nweight/tweight</span><br></pre></td></tr></table></figure><p></p><p>和kNN算法一样，该函数根据数据集与vec1的距离进行排序，并根据距离确定权重值。如果价格落入指定范围区间内，则计入tweight。所有近邻的权重值之和计入tweight。价格落入low到high区间内的概率，等于nweight/tweight。</p><p>我们来测试一下这个函数：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">probguess(data,[<span class="number">99</span>,<span class="number">20</span>],<span class="number">40</span>,<span class="number">80</span>)</span><br><span class="line"><span class="comment"># 0.62305988451497296</span></span><br><span class="line">probguess(data,[<span class="number">99</span>,<span class="number">20</span>],<span class="number">80</span>,<span class="number">120</span>)</span><br><span class="line"><span class="comment"># 0.37694011548502687</span></span><br><span class="line">probguess(data,[<span class="number">99</span>,<span class="number">20</span>],<span class="number">120</span>,<span class="number">1000</span>)</span><br><span class="line"><span class="comment"># 0.0</span></span><br><span class="line">probguess(data,[<span class="number">99</span>,<span class="number">20</span>],<span class="number">30</span>,<span class="number">120</span>)</span><br><span class="line"><span class="comment"># 1.0</span></span><br></pre></td></tr></table></figure><p></p><p>函数给出了一个合理的执行结果：位于实际价格区间之外的概率为0，而覆盖全部价格区间的概率接近于1。通过将区间拆分为更小的区段，我们可以确定出每一瓶葡萄酒所倾向的价格范围。这要求我们要考虑不同的区间，不同的区间大小进行测试，直到我们对整体的概率图有一个清晰的认识为止。下一小节，我们将学习绘制概率分布整体视图的方法。</p><h3 id="绘制概率分布整体视图"><a href="#绘制概率分布整体视图" class="headerlink" title="绘制概率分布整体视图"></a>绘制概率分布整体视图</h3><p>我们使用matplotlib这个数学图像库来回执概率分布图。<br>我们先用matplotlib来绘制一个简单的图形:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> *</span><br><span class="line">a=array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line">b=array([<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>])</span><br><span class="line">plot(a,b)</span><br><span class="line">show()</span><br><span class="line"><span class="comment">#arange函数构造一个数组，起始数值为0.0,终止数值为10.0,步长为0.1</span></span><br><span class="line">t1=arange(<span class="number">0.0</span>,<span class="number">10.0</span>,<span class="number">0.1</span>)</span><br><span class="line">plot(t1,sin(t1))</span><br><span class="line">show()</span><br></pre></td></tr></table></figure><p></p><p>上述代码绘制的图形如下图所示。我们绘制的是定义域0~10的正弦曲线。<br><img src="/2018/02/23/buildingPriceModels/sample.jpg" title="使用matplotlib进行绘图的例子"><br>我们将用两种方法来绘制概率图，第一种是累积概率图，第二种为概率密度图。下面我们依次介绍两种绘制方法。</p><h4 id="累积概率图"><a href="#累积概率图" class="headerlink" title="累积概率图"></a>累积概率图</h4><p>累积概率图显示的是结果小给定值的概率的分布情况。<br>以价格为例：概率为0开始，而后横轴上价格的增高，商品小于该价格的概率就越大，直到最高价格处，概率值达到1（实际价格小于或等于该价格的概率为100%）。<br>我们要得到指定价格与概率的对应关系，此处的概率的含义为商品预测价格小于指定价格的概率。我们的指定价格从0开始，以某个指定值为上限。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cumulativegraph</span><span class="params">(data,vec1,high,k=<span class="number">5</span>,weightf=gaussian)</span>:</span></span><br><span class="line">    t1 = arange(<span class="number">0.0</span>,high,<span class="number">0.1</span>)</span><br><span class="line">    cprob = array([probguess(data,vec1,<span class="number">0</span>,v,k,weightf) <span class="keyword">for</span> v <span class="keyword">in</span> t1])</span><br><span class="line">    plot(t1,cprob)</span><br><span class="line">    show()</span><br></pre></td></tr></table></figure><p></p><p>我们调用该函数，以生成图形:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cumulativegraph(data,(<span class="number">1</span>,<span class="number">1</span>),<span class="number">120</span>)</span><br></pre></td></tr></table></figure><p></p><p>生成的图形如下所示。<br><img src="/2018/02/23/buildingPriceModels/cumulative.jpg" title="累积概率图"><br>正如我们所期望的，累积概率从概率为0开始，并一路递增至1。从图中我们看出，小于50元的概率为0，然后在66左右快速升至0.6，然后一直保持状态，知道110元处附近，再一次发生跳跃。<br>通过观察图形，我们可以清楚的看到，高概率集中在60元和110两个价格点附近，因为这两个点是累积概率发生跳跃的地方。</p><h4 id="概率密度图"><a href="#概率密度图" class="headerlink" title="概率密度图"></a>概率密度图</h4><p>概率密度图尝试将处于不同价位点的实际概率值绘制出来。<br>由于任何一瓶葡萄酒准确的位于某一个价格的概率是非常低的，这样绘制出来的图像，预测价格附处会有一个小小的突起，而其余的地方则几乎都是0。我们需要一种方法可以将一个“窗口”范围内的概率值组合起来。为此，我们假设每个价位点的概率都等于其周边概率的一个加权平均，这与kNN算法类似。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">probabilitygraph</span><span class="params">(data,vec1,high,k=<span class="number">5</span>,weightf=gaussian,ss=<span class="number">5.0</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 建立一个代表价格的数组</span></span><br><span class="line">    t1 = arange(<span class="number">0.0</span>,high,<span class="number">0.1</span>)</span><br><span class="line">    <span class="comment">#得到整个定义域各个价格点的概率数组</span></span><br><span class="line">    probs = [probguess(data,vec1,v,v+<span class="number">0.1</span>,k,weightf) <span class="keyword">for</span> v <span class="keyword">in</span> t1]</span><br><span class="line">    <span class="comment">#通过加上近邻概率的高斯计算结果，对概率做平滑处理</span></span><br><span class="line">    smoothed=[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(probs)):</span><br><span class="line">        sv = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">0</span>,len(probs)):</span><br><span class="line">            dist = abs(i-j)*<span class="number">0.1</span><span class="comment">#计算距离</span></span><br><span class="line">            weight = gaussian(dist,sigma=ss)</span><br><span class="line">            sv+=weight*probs[j]</span><br><span class="line">        smoothed.append(sv)</span><br><span class="line">    smoothed = array(smoothed)</span><br><span class="line">    plot(t1,smoothed)</span><br><span class="line">    show()</span><br></pre></td></tr></table></figure><p></p><p>函数会构造一个从0-high的价格区间，然后计算量预测价格是该区间中各个价格的概率。这样的图形会有明显的锯齿，因此我们将该价格处的概率值追加上相邻价格的概率做加权平均，做平滑处理。经过平滑处理后的每个数据点，其对应的概率值都是邻近概率的高斯加权和。参数ss指定了概率被平滑处理的程度。<br>运行该函数:<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">probabilitygraph(data,(<span class="number">1</span>,<span class="number">1</span>),<span class="number">6</span>)</span><br></pre></td></tr></table></figure><p></p><p>我们会得到如下的图形:<br><img src="/2018/02/23/buildingPriceModels/density.jpg" title="概率密度图"><br>通过上图我们可以更加清楚的看到结果集中分布的区域。请尝试不同的窗口参数ss，看看图形会如何变化。<br>这样的概率分布图清晰的反映出，我们在预测葡萄酒价格时缺少了一部分关键数据，这个关键数据的形式是某些人会把葡萄酒卖的价格更高，而有的人会把葡萄酒的价格卖的比较低。<br>有些时候，你必须指示出缺少的关键数据是什么。有的时候，你仅仅是为了减少自己的支出时，你只需要知道，应该到哪买该商品，才可以用更低的价格买下该商品。</p><h1 id="何时使用k-最近邻算法"><a href="#何时使用k-最近邻算法" class="headerlink" title="何时使用k-最近邻算法"></a>何时使用k-最近邻算法</h1><p>何时使用KNN算法<br>kNN算法也存在不足:</p><ol><li>算法要计算当前测试项与数据集中每一项的距离，还需要排序，因此算法计算量大。</li><li>存在许多属性的时候，需要确定每个属性的权重、以及是否可以去除这个变量。我们可以使用优化算法来自动确定权重，但对于大数据而言，寻找最佳权重组合需要的时间比较长。</li></ol><p>kNN算法的优势：</p><ol><li>将新的数据加入数据集不需要任何开销，没有“训练”的过程（像朴素贝叶斯、神经网络，新加入数据集需要对其进行“训练”）。算法在预测的时候才有可能使用该数据进行加权平均。</li><li>确定了每个属性的权重后，我们可以更好的掌握数据的特征，哪些是关键因素。</li></ol><p>最后，当我们怀疑数据集中还有其他无法度量的属性时，可以建立概率密度视图。</p><h1 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h1></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>如果您觉得读完本文有收获，不妨小额赞助我一下，让我有动力继续写出高质量的教程！</div><button id="rewardButton" disable="enable"><span>打赏</span></button><div id="QR" style="display:block"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/smacker.jpg" alt="倔强的土豆 微信支付"><p>微信支付</p></div></div></div></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/02/02/decision-tree/" rel="next" title="决策树建模"><i class="fa fa-chevron-left"></i> 决策树建模</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018/02/26/advanced-classification/" rel="prev" title="advanced_classification">advanced_classification <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div><div class="comments" id="comments"><div id="gitment-container"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div id="sidebar-dimmer"></div><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">倔强的土豆</p><p class="site-description motion-element" itemprop="description">分享机器学习、深度学习的点滴</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">日志</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/laiqun" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:laiqun@msn.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#构造一个样本数据集"><span class="nav-number">1.</span> <span class="nav-text">构造一个样本数据集</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#k-近邻算法"><span class="nav-number">2.</span> <span class="nav-text">k-近邻算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#近邻数的选择"><span class="nav-number">2.1.</span> <span class="nav-text">近邻数的选择</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#近邻数过少"><span class="nav-number">2.1.1.</span> <span class="nav-text">近邻数过少</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#近邻数过多"><span class="nav-number">2.1.2.</span> <span class="nav-text">近邻数过多</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#定义相似度的度量方法"><span class="nav-number">2.2.</span> <span class="nav-text">定义相似度的度量方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#k最近邻算法的代码"><span class="nav-number">2.3.</span> <span class="nav-text">k最近邻算法的代码</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#加权kNN"><span class="nav-number">2.4.</span> <span class="nav-text">加权kNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#为近邻分配权重"><span class="nav-number">2.4.1.</span> <span class="nav-text">为近邻分配权重</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#加权kNN的代码实现"><span class="nav-number">2.4.2.</span> <span class="nav-text">加权kNN的代码实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉验证"><span class="nav-number">2.5.</span> <span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#处理不同属性"><span class="nav-number">2.6.</span> <span class="nav-text">处理不同属性</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#增加两个新属性——酒瓶容量与生产流水线编号"><span class="nav-number">2.6.1.</span> <span class="nav-text">增加两个新属性——酒瓶容量与生产流水线编号</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将不同值域的属性缩放到同一值域"><span class="nav-number">2.6.2.</span> <span class="nav-text">将不同值域的属性缩放到同一值域</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对缩放因子进行优化"><span class="nav-number">2.6.3.</span> <span class="nav-text">对缩放因子进行优化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#不对称分布"><span class="nav-number">2.7.</span> <span class="nav-text">不对称分布</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#估计概率密度"><span class="nav-number">2.7.1.</span> <span class="nav-text">估计概率密度</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#绘制概率分布整体视图"><span class="nav-number">2.7.2.</span> <span class="nav-text">绘制概率分布整体视图</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#累积概率图"><span class="nav-number">2.7.2.1.</span> <span class="nav-text">累积概率图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#概率密度图"><span class="nav-number">2.7.2.2.</span> <span class="nav-text">概率密度图</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#何时使用k-最近邻算法"><span class="nav-number">3.</span> <span class="nav-text">何时使用k-最近邻算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#练习"><span class="nav-number">4.</span> <span class="nav-text">练习</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">倔强的土豆</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script><link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css"><script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script><script type="text/javascript">function renderGitment(){var a=new Gitmint({id:window.location.pathname,owner:"laiqun",repo:"laiqun.github.io",lang:navigator.language||navigator.systemLanguage||navigator.userLanguage,oauth:{client_secret:"55aaeb736714431ea52109dd66461b1644ca6177",client_id:"c90dfa80285ea91b9120"}});a.render("gitment-container")}renderGitment()</script></body></html><!-- rebuild by neat -->