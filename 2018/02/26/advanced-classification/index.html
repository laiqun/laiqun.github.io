<!-- build time:Sun Jun 03 2018 18:33:06 GMT+0800 (CST) --><!DOCTYPE html><html class="theme-next mist" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3"><link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222"><meta name="keywords" content="Hexo, NexT"><meta name="description" content="前面几章已经讨论了三种分类器：神经网络、决策树、贝叶斯分类器。本章将介绍线性分类器与核方法的概念，并以此为铺垫介绍支持向量机（SVM）。本章要解决的问题是约会网站的用户配对，即给定两人的许多属性，属性有名词型也有数值型，属性直接还存在大量的非线性关系。我们将选用该约会网站的数据集来为大家示范前面几种分类器的缺陷，以及怎"><meta property="og:type" content="article"><meta property="og:title" content="高阶分类：核方法与SVM"><meta property="og:url" content="laiqun.github.io/2018/02/26/advanced-classification/index.html"><meta property="og:site_name" content="广阔天地，大有作为"><meta property="og:description" content="前面几章已经讨论了三种分类器：神经网络、决策树、贝叶斯分类器。本章将介绍线性分类器与核方法的概念，并以此为铺垫介绍支持向量机（SVM）。本章要解决的问题是约会网站的用户配对，即给定两人的许多属性，属性有名词型也有数值型，属性直接还存在大量的非线性关系。我们将选用该约会网站的数据集来为大家示范前面几种分类器的缺陷，以及怎样对数据集进行调整才能更好的适用前述算法。通过本章我们还会了解到这样一个事实：那"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="/2018/02/26/advanced-classification/scatter.png"><meta property="og:image" content="/2018/02/26/advanced-classification/decision.jpg"><meta property="og:image" content="/2018/02/26/advanced-classification/boundary.jpg"><meta property="og:image" content="/2018/02/26/advanced-classification/linear.png"><meta property="og:image" content="/2018/02/26/advanced-classification/vector.jpg"><meta property="og:image" content="/2018/02/26/advanced-classification/dot.jpg"><meta property="og:image" content="/2018/02/26/advanced-classification/linear.png"><meta property="og:image" content="/2018/02/26/advanced-classification/circle.jpg"><meta property="og:image" content="/2018/02/26/advanced-classification/square.jpg"><meta property="og:image" content="/2018/02/26/advanced-classification/svm1.jpg"><meta property="og:image" content="/2018/02/26/advanced-classification/svm2.jpg"><meta property="og:updated_time" content="2018-06-02T14:05:48.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="高阶分类：核方法与SVM"><meta name="twitter:description" content="前面几章已经讨论了三种分类器：神经网络、决策树、贝叶斯分类器。本章将介绍线性分类器与核方法的概念，并以此为铺垫介绍支持向量机（SVM）。本章要解决的问题是约会网站的用户配对，即给定两人的许多属性，属性有名词型也有数值型，属性直接还存在大量的非线性关系。我们将选用该约会网站的数据集来为大家示范前面几种分类器的缺陷，以及怎样对数据集进行调整才能更好的适用前述算法。通过本章我们还会了解到这样一个事实：那"><meta name="twitter:image" content="/2018/02/26/advanced-classification/scatter.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",version:"5.1.3",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!0},fancybox:!0,tabs:!0,motion:{enable:!1,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="laiqun.github.io/2018/02/26/advanced-classification/"><title>高阶分类：核方法与SVM | 广阔天地，大有作为</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">广阔天地，大有作为</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">你看到我的筋斗云了嘛？</p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br>关于</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="laiqun.github.io/2018/02/26/advanced-classification/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="倔强的土豆"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="广阔天地，大有作为"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">高阶分类：核方法与SVM</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-02-26T22:40:09+08:00">2018-02-26 </time></span><span class="post-comments-count"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-comment-o"></i> </span><a href="/2018/02/26/advanced-classification/#comments" itemprop="discussionUrl"><span class="post-comments-count gitment-comments-count" data-xid="/2018/02/26/advanced-classification/" itemprop="commentsCount"></span></a></span></div></header><div class="post-body" itemprop="articleBody"><p>前面几章已经讨论了三种分类器：神经网络、决策树、贝叶斯分类器。本章将介绍线性分类器与核方法的概念，并以此为铺垫介绍支持向量机（SVM）。<br>本章要解决的问题是约会网站的用户配对，即给定两人的许多属性，属性有名词型也有数值型，属性直接还存在大量的非线性关系。<br>我们将选用该约会网站的数据集来为大家示范前面几种分类器的缺陷，以及怎样对数据集进行调整才能更好的适用前述算法。<br>通过本章我们还会了解到这样一个事实：那就是将一个复杂数据集扔给算法，然后寄希望于它能够学会如何进行精确分类，这几乎是不可能的；<strong>选择正确的算法，然后对数据进行适当的预处理，这是获得满意的分类结果所必须的。</strong></p><h1 id="数据集介绍"><a href="#数据集介绍" class="headerlink" title="数据集介绍"></a>数据集介绍</h1><p>本章的假设的背景是一个在线约会网站，要预测具备某些条件、爱好的一对人是否能成为朋友。<br>人物 | 年龄 | 是否吸烟 | 是否要孩子？ | 兴趣列表 | 家庭住址 | 交往状态<br>— | — | — | — | — | — | —<br>1号 | 39 | yes | no | skiing:knitting:dangcing | New York | NY（not yet）还没有<br>2号 | 43 | no | yes | soccer:reading:scrabble | New York | 0(表决定见面)<br>3号 | 23 | no | no | football:fashion | New York | NY(还没有)<br>4号 | 30 | no | no | snowboarding:knitting:computers:shopping:tv:travel | New York | 1（已经交往）</p><p>利用这些数据我们可以得知网站现在的主体用户群，来改善我们的网站推广策略。</p><p>为了演示分类器的工作原理，我们现在只考虑这个数据集中的三个属性：年龄和性别和是否配对(交往状态)。</p><p>我们的数据集是csv格式的，我们先写一个加载和解析数据集的函数<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取交往状态信息</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">matchrow</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,row,allnum=False)</span>:</span></span><br><span class="line">	<span class="comment"># row代表一行数据；allnum为true的时候表示该数据集中所有属性都是数字型数据</span></span><br><span class="line">		<span class="keyword">if</span> allnum:</span><br><span class="line">			<span class="comment">#如果是数字型，将全部属性转换为float</span></span><br><span class="line">			self.data=[float(row[i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(len(row)<span class="number">-1</span>)]</span><br><span class="line">		<span class="keyword">else</span>:</span><br><span class="line">			self.data=row[<span class="number">0</span>:len(row)<span class="number">-1</span>]</span><br><span class="line">		self.match=int(row[len(row)<span class="number">-1</span>])<span class="comment">#最后一行的是否配对只有0和1两种取值</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadmatch</span><span class="params">(f,allnum=Flase)</span>:</span></span><br><span class="line">	rows=[]</span><br><span class="line">	<span class="keyword">for</span> line <span class="keyword">in</span> file(f):</span><br><span class="line">		rows.append(matchrow(line.split(<span class="string">','</span>),allnum))</span><br><span class="line">	<span class="keyword">return</span> rows</span><br></pre></td></tr></table></figure><p></p><p>loadmatch函数的作用是构造一个matchrow类的列表，列表中的每一项元素均包含了原始数据、以及配对信息。</p><h1 id="可视化数据集"><a href="#可视化数据集" class="headerlink" title="可视化数据集"></a>可视化数据集</h1><p>我们这一小节将使用matplotlib来可视化数据集，该数据集只含有性别、年龄、和配对情况的信息。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> *</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotagematches</span><span class="params">(rows)</span>:</span></span><br><span class="line">	xdm,ydm=[r.data[<span class="number">0</span>] <span class="keyword">for</span> r <span class="keyword">in</span> rows <span class="keyword">if</span> r.match==<span class="number">1</span>,r.data[<span class="number">1</span>] <span class="keyword">for</span> r <span class="keyword">in</span> rows <span class="keyword">if</span> match==<span class="number">1</span>]<span class="comment">#打印配对的点</span></span><br><span class="line">	xdn,ydn=[r.data[<span class="number">0</span>] <span class="keyword">for</span> r <span class="keyword">in</span> rows <span class="keyword">if</span> r.match==<span class="number">0</span>,r.data[<span class="number">1</span>] <span class="keyword">for</span> r <span class="keyword">in</span> rows <span class="keyword">if</span> match==<span class="number">0</span>]<span class="comment">#打印不配对的点</span></span><br><span class="line">	plot(xdm,ydm,<span class="string">'go'</span>)<span class="comment">#配对的坐标点标记为实心远点</span></span><br><span class="line">	plot(xdn,ydn,<span class="string">'ro'</span>)<span class="comment">#不配对的坐标点标记为“+”</span></span><br></pre></td></tr></table></figure><p></p><img src="/2018/02/26/advanced-classification/scatter.png" title="根据年龄与配对情况得到的散布图"><p>该数据只考虑了年龄和性别，从图中我们看出两种标注点之间存在明显的边界，但边界并不是一条直线就可以分开；另外，从图中我们可以观察出年龄越大能忍受的年龄差距就越大。图中黄色矩形标注表现为20岁只和20的异性交往；而图中红色矩形标注表明50岁的男人可以和28-50岁的女人交往。<br>从这些现象可以看出该数据集有两个值得注意的地方，第一个是变量的相互作用；另外，数据集并不是线性的，使用简单的线性分类器无法完美的将数据集进行划分。</p><h1 id="使用决策树分类器做数据划分"><a href="#使用决策树分类器做数据划分" class="headerlink" title="使用决策树分类器做数据划分"></a>使用决策树分类器做数据划分</h1><p>前面我们提到了决策树分类器，我们可以利用树来对数据进行自动分类。前面我们介绍的决策树时使用的数值边界来对数据进行划分的。<br>值得注意的是对于本章的数据集来说，使用年龄差作为分类依据似乎更加稳妥，不过决策树是无法对输入变量进行复杂计算的。</p><img src="/2018/02/26/advanced-classification/decision.jpg" title="反应决策边界的决策树"> <img src="/2018/02/26/advanced-classification/boundary.jpg" title="根据决策树生成的边界线"><p>我们可以看出决策树的边界有些过于死板，边界线的线段要么是水平，要么是垂直的。位于边界线两侧的数据应该是不同的分类。<br>从这里我们可以得出两个结论：</p><ol><li>在没有弄清楚数据的含义，并将它们转换为易于理解的形式之前，轻率的套用模型往往不可靠。建立<strong>散布图</strong>有利于我们找到数据真正的划分方式。</li><li>决策树有易于解释的特点，但如果存在多个数值型输入，而且数据之间可能会存在相互作用，此时决策树往往不是有效的做法。</li></ol><h1 id="使用基本的线性分类对数据进行划分"><a href="#使用基本的线性分类对数据进行划分" class="headerlink" title="使用基本的线性分类对数据进行划分"></a>使用基本的线性分类对数据进行划分</h1><p>线性分类器的工作原理是寻找每个分类的分类中心，分类中心的计算方法为对该分类的所有数据取平均值。这时候有新来的一个数据，我们可以判断该数据离哪个分类中心更近，从而预测它应该属于哪个分类。<br>我们来编写每个分类的分类中心的函数：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">lineartrain</span><span class="params">(rows)</span>:</span></span><br><span class="line">	averages=&#123;&#125;</span><br><span class="line">	<span class="comment">#averages示例：&#123;'0':[26,35],'1':[35,33]&#125;  0代表第一个分类，其分类中心的坐标点为[26,35]；1代表第二个分类，其分类中心坐标点为[35,33]</span></span><br><span class="line">	counts=&#123;&#125;</span><br><span class="line">	<span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">		<span class="comment">#得到这个坐标点的属于哪个分类</span></span><br><span class="line">		cl = row.match</span><br><span class="line">		averages.setdefault(cl,[<span class="number">0.0</span>]*len(row.data))</span><br><span class="line">		counts.setdefault(cl,<span class="number">0</span>)</span><br><span class="line">		<span class="comment">#将该坐标加入到averages中</span></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> range(len(row.data)):</span><br><span class="line">			averages[cl][i]+float(row.data[i])</span><br><span class="line">		<span class="comment">#记录该分类的有多少个数据项，计算分类中心的时候（计算平均值）</span></span><br><span class="line">		<span class="comment">#计算平均值  公式：总和除上该分类的计数</span></span><br><span class="line">		<span class="keyword">for</span> cl,avg <span class="keyword">in</span> averages.items():</span><br><span class="line">			<span class="keyword">for</span> i <span class="keyword">in</span> range(len(avg)):</span><br><span class="line">				avg[i]/=counts[cl]</span><br><span class="line">	<span class="keyword">return</span> averages</span><br></pre></td></tr></table></figure><p></p><p>下图中的红色圆圈表示计算得到的不同的分类中心。划分数据的直线应该位于两个分类中心的中间位置。这意味着位于直线左侧的数据更接近于不相匹配；位于直线右侧的数据更接近于相匹配。当有新数据要进行预测的时候，我们只需要计算它与那个分类中心更近，就可以得知它应该属于哪个分类。<br><img src="/2018/02/26/advanced-classification/linear.png" title="利用均值的线性分类器"><br>有多中方法可以度量一个坐标点距离分类中心的远近：一种计算远近的度量公式为欧几里得距离。我们也可以使用向量的点积来计算，此处使用点积是为了后续扩展。</p><p>向量具有大小和方向，我们时常将其表示成平面上的一个箭头，或者记做一个数字集合。下图给出了一些示例，图中还示范了一个点减去另外一个点，得了连接这两个点的向量。<br><img src="/2018/02/26/advanced-classification/vector.jpg" title="向量的例子"><br>点积是指，针对两个向量，将第一个向量与第二个向量的对应值相乘，然后将所有的乘积相加。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dotproduct</span><span class="params">(v1,v2)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> sum([v1[i]*v2[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(v1))])</span><br></pre></td></tr></table></figure><p></p><p>点积也可以利用两个向量的长度乘积，再乘上两者夹角的余弦值得到。如果夹角大于90度，那么夹角的余弦值为负数，这意味着点积也为负数。如果小于90度，点积则为正数。<br><img src="/2018/02/26/advanced-classification/dot.jpg" title="利用点积来确定距离"><br>在上图中，我们有两个分类中心，分别是M0和M1，分别代表“匹配”和“不匹配”。C点位于M0和M1中间，另外还有两个点X0和X1，它们是要被分类的坐标点。<br>在图中X1应该更接近M0，它应该被划分到“匹配”分类中。我们注意到向量X1-&gt;C与向量M0-&gt;C的夹角为45度，45度小于90度，故它们的点积为正数。同理，向量X1-&gt;C与向量M0-&gt;M1的点积也为正数。<br>在图中X2应该更接近M1，它应该被划分到“不匹配”分类中。我们注意到向量X2-&gt;C与向量M0-&gt;C的夹角为105度（以点C为中心，X2-&gt;逆时针转105度，方向便与向量M0-&gt;C重叠），105度大于90度，故它们的点积为负数。同理，向量X2-&gt;C与向量M0-&gt;M1的点积也为正数。</p><p>夹角大于90度结果为负数，小于90度结果为正数，我们只需要观察点积结果的正负号，就可以得知一个新坐标点应该属于哪个分类。<br>C点是M0与M1的中间点，故C为(M0+M1)/2。<br>class=sign((X-C)·(M0-M1))=sign((X-(M0+M1)/2)·(M0-M1))<br>上述公式中sign为取符号函数。<br>将上述公式进行展开得到:<br>class=sign(X·M0-X·M1+(M0·M0-M1·M1)/2)<br>我们将利用上述公式来进行分类，(M0·M0-M1·M1)/2视为变量offset,我们将其编写为函数。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dpclassify</span><span class="params">(point,avgs)</span>:</span> <span class="comment">#avgs中存放的是两个分类中心</span></span><br><span class="line">	offset = (dotproduct(avgs[<span class="number">0</span>],avgs[<span class="number">0</span>])-dotproduct(avgs[<span class="number">1</span>],avgs[<span class="number">1</span>]))/<span class="number">2</span></span><br><span class="line">	y=dotproduct(point,avgs[<span class="number">0</span>])-dotproduct(point,avgs[<span class="number">1</span>])+b</span><br><span class="line">	<span class="keyword">if</span> y&gt;<span class="number">0</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure><p></p><p>我们来测试一下这个函数：<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">dpclassify([<span class="number">30</span>,<span class="number">30</span>],avgs)</span><br><span class="line"><span class="comment">#1</span></span><br><span class="line">dpclassify([<span class="number">30</span>,<span class="number">25</span>],avgs)</span><br><span class="line"><span class="comment">#1</span></span><br><span class="line">dpclassify([<span class="number">25</span>,<span class="number">40</span>],avgs)</span><br><span class="line"><span class="comment">#0</span></span><br><span class="line">dpclassify([<span class="number">48</span>,<span class="number">20</span>],avgs)</span><br><span class="line"><span class="comment">#1</span></span><br></pre></td></tr></table></figure><p></p><p>请记住这是一个线性分类器，它只找出了一条分界线。这意味着如果找不到一条划分数据的直线或者实际存在多条直线才能较好的划分数据的时候，此时分类器就会得到错误的答案。<br>下图中的坐标点(48,20)位于直线的右侧，因此得到了”匹配”的错误预测。在“理解核方法”小节我们将对其进行改进，使其能够处理非线性的分类。<br><img src="/2018/02/26/advanced-classification/linear.png" title="利用均值的线性分类器"></p><h1 id="将数据都转化为数值类型"><a href="#将数据都转化为数值类型" class="headerlink" title="将数据都转化为数值类型"></a>将数据都转化为数值类型</h1><p>数据集中不仅还有数值数据，还有文本类型的数据。像决策树是不需要对数据进行任何预处理就可以处理这两种类型的数据。而这里的分类器只能处理数值型数据。为了解决这个问题，我们需要将数据都转换为数值类型。</p><h2 id="将是-否问题转换为数值"><a href="#将是-否问题转换为数值" class="headerlink" title="将是/否问题转换为数值"></a>将是/否问题转换为数值</h2><p>对于是/否问题，我们可以将“是”转换为1，“否”转换为-1，对于缺失或者模棱两可的情况转换为0。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">yesno</span><span class="params">(v)</span>:</span></span><br><span class="line">	<span class="keyword">if</span> v==<span class="string">'yes'</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">	<span class="keyword">elif</span> v==<span class="string">'no'</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="number">-1</span></span><br><span class="line">	<span class="keyword">else</span>:</span><br><span class="line">		<span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure><p></p><h2 id="将一对恋人的兴趣列表转换为数值"><a href="#将一对恋人的兴趣列表转换为数值" class="headerlink" title="将一对恋人的兴趣列表转换为数值"></a>将一对恋人的兴趣列表转换为数值</h2><p>我们可以将每一个兴趣都看成一个数值变量，有这个兴趣就写1，否则写0。<br>但我们这里处理的是一对男女的兴趣，我们可以将共同爱好的数量视作变量。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matchcount</span><span class="params">(interest1,interest2)</span>:</span></span><br><span class="line">	l1 = interest1.split(<span class="string">':'</span>)</span><br><span class="line">	l2 = interest2.split(<span class="string">':'</span>)</span><br><span class="line">	x=<span class="number">0</span></span><br><span class="line">	<span class="keyword">for</span> v <span class="keyword">in</span> l1:</span><br><span class="line">		<span class="keyword">if</span> v <span class="keyword">in</span> l2:</span><br><span class="line">			x+=<span class="number">1</span></span><br><span class="line">	<span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p></p><p>将共同爱好的数量当做特征也会护士一些其他信息，比如说其实某些不同兴趣爱好的组合也可能配对成功，比如滑雪和滑板、喝酒喝跳舞。如果分类器没有在未经这样处理的原始数据上进行训练，是无法学习到这样的组合的。<br>如果将每一个兴趣都看成一个变量，这回导致变量过多。一种抑制变量过多的方法是做好层级分类，比如说，滑雪和滑板都属于体育运动中雪地运动分支，如果两个人对雪地运动都感兴趣，但是又不是同一个项目，我们可以将mathcount的数值加0.8，而不是满分1。共同爱好越靠近在上一级，得到的分数就越小。</p><h2 id="将经纬度坐标转换为欧几里得距离"><a href="#将经纬度坐标转换为欧几里得距离" class="headerlink" title="将经纬度坐标转换为欧几里得距离"></a>将经纬度坐标转换为欧几里得距离</h2><p>两个人住的越近就越可能匹配成功。首先我们需要根据数据集中的地址来得到地址的经纬度，这项工作可以用Yahoo Maps提供的Geocoding服务来解决。<br>该API的请求地址是<a href="http://api.local.yahoo.com/MapsService/V1/geocode?appid=appid&amp;location=location，其中appid为你申请的应用id，location是一个地址、或者邮编、城市名或者州名。" target="_blank" rel="noopener">http://api.local.yahoo.com/MapsService/V1/geocode?appid=appid&amp;location=location，其中appid为你申请的应用id，location是一个地址、或者邮编、城市名或者州名。</a><br>该API的返回结果为XML文件：<br></p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ResultSet</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Result</span> <span class="attr">precision</span>=<span class="string">"address"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Latitude</span>&gt;</span>37.417312<span class="tag">&lt;/<span class="name">Latitude</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Longitude</span>&gt;</span>-122.026419<span class="tag">&lt;/<span class="name">Longitude</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Address</span>&gt;</span>755 FIRST AVE<span class="tag">&lt;/<span class="name">Address</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">City</span>&gt;</span>SUNNYVALE<span class="tag">&lt;/<span class="name">City</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">State</span>&gt;</span>CA<span class="tag">&lt;/<span class="name">State</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Zip</span>&gt;</span>94089-1019<span class="tag">&lt;/<span class="name">Zip</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">Country</span>&gt;</span>US<span class="tag">&lt;/<span class="name">Country</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">Result</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;/<span class="name">ResultSet</span>&gt;</span></span><br></pre></td></tr></table></figure><p></p><p>我们只关注结果中的longtitue和latitude，为了解析XML，我们需要使用minidom。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yahookey=<span class="string">"Your Key Here"</span></span><br><span class="line"><span class="keyword">from</span> xml.dom.minidom <span class="keyword">import</span> parseString</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> urlopen,quote_plus</span><br><span class="line">loc_cache=&#123;&#125;</span><br><span class="line">     <span class="function"><span class="keyword">def</span> <span class="title">getlocation</span><span class="params">(address)</span>:</span></span><br><span class="line">       <span class="keyword">if</span> address <span class="keyword">in</span> loc_cache: <span class="keyword">return</span> loc_cache[address]</span><br><span class="line">       data=urlopen(<span class="string">'http://api.local.yahoo.com/MapsService/V1/'</span>+\</span><br><span class="line">       	<span class="string">'geocode?appid=%s&amp;location=%s'</span> % (yahookey,quote_plus(address))).read( ) doc=parseString(data)</span><br><span class="line">       lat=doc.getElementsByTagName(<span class="string">'Latitude'</span>)[<span class="number">0</span>].firstChild.nodeValue</span><br><span class="line">       long=doc.getElementsByTagName(<span class="string">'Longitude'</span>)[<span class="number">0</span>].firstChild.nodeValue</span><br><span class="line">       loc_cache[address]=(float(lat),float(long))</span><br><span class="line">       <span class="keyword">return</span> loc_cache[address]</span><br></pre></td></tr></table></figure><p></p><p>上述代码利用应用密钥和位置信息构造了一个URL，然后请求网站，得到该地址对应的经纬度。</p><h3 id="根据经纬度计算距离"><a href="#根据经纬度计算距离" class="headerlink" title="根据经纬度计算距离"></a>根据经纬度计算距离</h3><p>要将两个经纬度坐标转换为英里的距离值，我们这里采用一种近似值的计算方法，与欧几里得距离的计算方法类似，不同之处在于将维度之差乘上69.1，经度之差乘上53。利用该方法计算得到的距离值会有小鱼10%的误差，这对于本章的应用是可以接受的。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">milesdistance</span><span class="params">(a1,a2)</span>:</span></span><br><span class="line">	lat1,long1=getlocation(a1)</span><br><span class="line">    lat2,long2=getlocation(a2)</span><br><span class="line">    latdif=<span class="number">69.1</span>*(lat2-lat1)</span><br><span class="line">    longdif=<span class="number">53.0</span>*(long2-long1)</span><br><span class="line">    <span class="keyword">return</span> (latdif**<span class="number">2</span>+longdif**<span class="number">2</span>)**<span class="number">.5</span></span><br></pre></td></tr></table></figure><p></p><p>我们来测试一下这个函数。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">milesdistance(<span class="string">'cambridge'</span>,<span class="string">'new york'</span>)</span><br><span class="line"><span class="comment">#191.77</span></span><br></pre></td></tr></table></figure><p></p><h2 id="将旧数据都转换为数值型的新数据"><a href="#将旧数据都转换为数值型的新数据" class="headerlink" title="将旧数据都转换为数值型的新数据"></a>将旧数据都转换为数值型的新数据</h2><p>上一小节我们给出了将数据集中的非数值类型转换为数值类型的方法，现在我们把数据集中的所有数据都转换为数值类型。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadnumerical</span><span class="params">()</span>:</span></span><br><span class="line">	oldrows = loadmatch(<span class="string">'matchmaker.csv'</span>)</span><br><span class="line">	newrows=[]</span><br><span class="line">	<span class="keyword">for</span> row <span class="keyword">in</span> oldrows:</span><br><span class="line">		d = row.data</span><br><span class="line">		data=[float(d[<span class="number">1</span>]),yesno(d[<span class="number">1</span>]),yesno(d[<span class="number">2</span>]),float(d[<span class="number">5</span>]),yesno(d[<span class="number">6</span>]),yesno(d[<span class="number">7</span>]),matchcount(d[<span class="number">3</span>],d[<span class="number">8</span>]),milesdistance(d[<span class="number">4</span>],d[<span class="number">9</span>]),row.match]</span><br><span class="line">		newrows.append(matchrow(data))</span><br><span class="line">	<span class="keyword">return</span> newrows</span><br></pre></td></tr></table></figure><p></p><p>该函数将原理的数据集中的每一行都生成一个新的数据行。</p><h1 id="对数据进行缩放-归一化"><a href="#对数据进行缩放-归一化" class="headerlink" title="对数据进行缩放(归一化)"></a>对数据进行缩放(归一化)</h1><p>我们发现不同的变量拥有不同的取值范围，是否想要孩子的数据介于-1到1之间，而年龄差的范围却比较巨大。是否想要孩子的信息最大差值为2，要比年龄差6岁这个信息有用的多，故最好不要将年龄和是否想要孩子这个信息等同对待。<br>我们可以将所有的数据都缩放到统一尺度，从而使得每个变量的差值都具有可比性。通过确定每个变量的最大值、最小值，对数据进行相应的缩放，使其最小值为0，最大值为1，其他值介于0-1之间，就可以在相同的尺度上对每个变量进行比较了。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scaledata</span><span class="params">(rows)</span>:</span></span><br><span class="line">      low=[<span class="number">999999999.0</span>]*len(rows[<span class="number">0</span>].data)</span><br><span class="line">      high=[<span class="number">-999999999.0</span>]*len(rows[<span class="number">0</span>].data)</span><br><span class="line">      <span class="comment"># 找到最大值和最小值</span></span><br><span class="line">      <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">        d=row.data</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(d)):</span><br><span class="line">          <span class="keyword">if</span> d[i]&lt;low[i]: low[i]=d[i]</span><br><span class="line">          <span class="keyword">if</span> d[i]&gt;high[i]: high[i]=d[i]</span><br><span class="line">      <span class="comment"># 对数据进行缩放</span></span><br><span class="line">      <span class="function"><span class="keyword">def</span> <span class="title">scaleinput</span><span class="params">(d)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> [(d.data[i]-low[i])/(high[i]-low[i])</span><br><span class="line">                 <span class="keyword">for</span> i <span class="keyword">in</span> range(len(low))]</span><br><span class="line">      <span class="comment"># Scale all the data</span></span><br><span class="line">      newrows=[matchrow(scaleinput(row.data)+[row.match])</span><br><span class="line">               <span class="keyword">for</span> row <span class="keyword">in</span> rows]</span><br><span class="line">      <span class="comment"># Return the new data and the function</span></span><br><span class="line">      <span class="keyword">return</span> newrows,scaleinput</span><br></pre></td></tr></table></figure><p></p><p>上述函数定义了一个内部函数scaleinput，其作用是找出最小值，并从所有数值中减去该最小值，从而将值域范围调整到0位起点。函数随后又初上最大值与最小值的差，从而将数据锁定在小于1的范围内。<br>现在要考虑的变量不仅仅是年龄了，只试图寻找一条分界线的局限越来越明显，我们需要一种能够超越线性分类器的新方法。</p><h1 id="理解核方法"><a href="#理解核方法" class="headerlink" title="理解核方法"></a>理解核方法</h1><p>试想一下，我们用线性分类器对下图中的数据分类会如何？<br><img src="/2018/02/26/advanced-classification/circle.jpg" title="环绕状"><br>每一个分类的均值点在哪儿？ 它们恰好都位于相同的位置！尽管我们可以一眼看出，内圈内的数据都是X，外圈的数据都是O，但是线性分类器无法识别这两个分类。<br>如果我们考虑与均值点的远近，也可以分类，因为分类中心虽然相同，但是X类别距离分类中心比O类别更近，如果我们可以考虑坐标到分类中心的距离（随后我们会知道，径向基函数是一个考虑距离的函数），则也可以完成分类的。<br>此时使用向量夹角也是无法分类的，因为向量都是指向圆心。<br>试想一下，如果先对每一个x与y的坐标点求平方，结果会如何呢？原来的(-1,2)变成(1,4)，原来的(0.5,1)变成（0.25，1），数据的新分布情况如下图所示：<br><img src="/2018/02/26/advanced-classification/square.jpg" title="新数据分布图"><br>所有的X都位于接近原点处，O类型位于原点角落之外的区域，此时可以使用一条直线来划分两种分类啦。对于一个带预测的数据，只需将其x与y都求平方，然后观察其位于该分界线的哪一侧即可。<br>上述的例子告诉我们，通过预先对坐标点进行变换，构造一个只用一条直线就可以划分的新数据集是完全有可能的。这里选的例子是非常容易变换的，在面对实际问题时，变换的方法可能要复杂的多，特征是数据存在多维变换的时候，比如我们将一个x与y坐标的数据集，变换成a、b、c三个坐标构成的新数据集，其中a=x^2,b=x*y,c=y^2，一旦数据位于多维空间，此时寻找分界线可能会变得更容易。</p><h2 id="核技法"><a href="#核技法" class="headerlink" title="核技法"></a>核技法</h2><p>尽管可以编写代码将数据按照上述方法变换到新的坐标空间中，但实际上我们通常不会这样去做，因为要找到一条鱼实际数据集相匹配的分界线，必须要将数据投影到成百上千个维度上，要实现这样的功能是非常不切实际的。然后，对于任何用到了点积运算的算法——包括线性分类器，都可以采用一种核技法的技术。<br>核技法的思路是用一个新的函数取代原来的点积函数，当借助某个映射函数将数据变换到高纬空间时，新函数将会返回高纬度坐标空间内的点积结果。此处，对于变换方法的数量没有任何的限制，但是实际使用中我们只采用几种变换方法，一种方法成为”径向基函数”。<br>径向基函数与点积类似，它接受两个向量作为参数，并返回一个标量值，两个向量距离距离越远，则径向基函数的值越小。与点积不同的是，径向基函数是非线性的，因此它能够将数据映射到更为复杂的空间中。<br>前面我们说过环绕状的两个分类考虑距离之后会变得可分，而径向基则起到计算与中心点距离的作用。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rbf</span><span class="params">(v1,v2,gamma=<span class="number">20</span>)</span>:</span></span><br><span class="line">	dv = [v1[i]-v2[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(v1))]</span><br><span class="line">	l = veclength(dv)</span><br><span class="line">	<span class="keyword">return</span> math.e**(-gamma*l)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">veclength</span><span class="params">(v)</span>:</span></span><br><span class="line">	<span class="keyword">return</span> sum([p**<span class="number">2</span> <span class="keyword">for</span> p <span class="keyword">in</span> v])<span class="comment">#表示(x-c)^2</span></span><br></pre></td></tr></table></figure><p></p><p>该函数接受一个gamma参数，我们可以对该参数进行调整，以得到一个针对给定数据集的最佳线性分类。<br>我们需要一个新的函数，计算坐标点变换后与变换后的均值点之间的距离。遗憾的是，均值点是在原始空间中计算得到的，因此无法直接使用它们——事实上，根本无法计算坐标点，因为实际上不会再新的坐标空间中计算坐标点的位置。（比如说径向基函数得到的其实是标量）。比较幸运的是先计算平均值再求点积（径向基），与先求点积（径向基），再计算平均值效果上是等价的，故我们先求点积，再算平均值。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nlclassify</span><span class="params">(point,rows,offset,gamma=<span class="number">10</span>)</span>:</span></span><br><span class="line">	sum0=<span class="number">0.0</span></span><br><span class="line">    sum1=<span class="number">0.0</span></span><br><span class="line">    count0=<span class="number">0</span></span><br><span class="line">    count1=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">    	<span class="keyword">if</span> row.match==<span class="number">0</span>:</span><br><span class="line">        	sum0+=rbf(point,row.data,gamma)</span><br><span class="line">        	count0+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        	sum1+=rbf(point,row.data,gamma)<span class="comment">#这里是先点积（径向基），再求平均值</span></span><br><span class="line">        	count1+=<span class="number">1</span></span><br><span class="line">		y=(<span class="number">1.0</span>/count0)*sum0-(<span class="number">1.0</span>/count1)*sum1+offset</span><br><span class="line">        <span class="keyword">if</span> y&lt;<span class="number">0</span>:</span><br><span class="line">        	<span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        	<span class="keyword">return</span> <span class="number">1</span></span><br><span class="line"> <span class="comment">#class=sign(X·M0-X·M1+(M0·M0-M1·M1)/2)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getoffset</span><span class="params">(rows,gamma=<span class="number">10</span>)</span>:</span><span class="comment">#这个函数就是求前面公式中的(M0·M0-M1·M1)/2)，只不过这里除的是n^2,因为共生成了n^2个点</span></span><br><span class="line">	l0=[]</span><br><span class="line">    l1=[]</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">    	<span class="keyword">if</span> row.match==<span class="number">0</span>:</span><br><span class="line">    		l0.append(row.data)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">        	l1.append(row.data)</span><br><span class="line">		sum0=sum(sum([rbf(v1,v2,gamma) <span class="keyword">for</span> v1 <span class="keyword">in</span> l0]) <span class="keyword">for</span> v2 <span class="keyword">in</span> l0)<span class="comment">#生成了n*n个点的求和</span></span><br><span class="line">		sum1=sum(sum([rbf(v1,v2,gamma) <span class="keyword">for</span> v1 <span class="keyword">in</span> l1]) <span class="keyword">for</span> v2 <span class="keyword">in</span> l1)</span><br><span class="line">		<span class="keyword">return</span> (<span class="number">1.0</span>/(len(l1)**<span class="number">2</span>))*sum1-(<span class="number">1.0</span>/(len(l0)**<span class="number">2</span>))*sum0</span><br></pre></td></tr></table></figure><p></p><p>数据集发生改变后，offset也会跟着改变，而且该计算过程比较费时，因此我们应该先为某个数据集计算一次便宜，然后再调用nlcalssify的时候传入该值。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">nlclassify([<span class="number">30</span>,<span class="number">30</span>],agesonly,offset)</span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line">nlclassify([<span class="number">30</span>,<span class="number">25</span>],agesonly,offset)</span><br><span class="line"><span class="comment"># 1</span></span><br><span class="line">nlclassify([<span class="number">25</span>,<span class="number">40</span>],agesonly,offset)</span><br><span class="line"><span class="comment"># 0</span></span><br><span class="line">nlclassify([<span class="number">48</span>,<span class="number">20</span>],agesonly,offset)</span><br><span class="line"><span class="comment"># 0</span></span><br></pre></td></tr></table></figure><p></p><p>非常好！现在我们的分类器能够识别一个年龄匹配的环状分布。我们现在可以将其他属性也包含进来，再试一下。<br></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ssoffset=getoffset(scaledset)</span><br><span class="line">numericalset[<span class="number">0</span>].match</span><br><span class="line"><span class="comment">#0</span></span><br><span class="line">nlclassify(scalef(numericalset[<span class="number">0</span>].data),scaledset,ssoffset) <span class="number">0</span></span><br><span class="line">numericalset[<span class="number">1</span>].match</span><br><span class="line"><span class="comment">#1</span></span><br><span class="line">nlclassify(scalef(numericalset[<span class="number">1</span>].data),scaledset,ssoffset) <span class="number">1</span></span><br><span class="line">numericalset[<span class="number">2</span>].match</span><br><span class="line"><span class="comment">#0</span></span><br><span class="line">nlclassify(scalef(numericalset[<span class="number">2</span>].data),scaledset,ssoffset) <span class="number">0</span></span><br><span class="line">newrow=[<span class="number">28.0</span>,<span class="number">-1</span>,<span class="number">-1</span>,<span class="number">26.0</span>,<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0.8</span>] <span class="comment"># Man doesn't want children, woman does </span></span><br><span class="line">nlclassify(scalef(newrow),scaledset,ssoffset)</span><br><span class="line"><span class="comment">#0</span></span><br><span class="line">newrow=[<span class="number">28.0</span>,<span class="number">-1</span>,<span class="number">1</span>,<span class="number">26.0</span>,<span class="number">-1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">0.8</span>] <span class="comment"># Both want children</span></span><br><span class="line">advancedclassify.nlclassify(scalef(newrow),scaledset,ssoffset)</span><br><span class="line"><span class="comment">#1</span></span><br></pre></td></tr></table></figure><p></p><p>我们可以看到，女方想要孩子，而男生不想要的话，即使他们的共同爱好很多，也不会匹配成功。</p><h1 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h1><p>继续前面的话题，当寻找一条划分两个分类的直线时我们所面临的困境，如下图所示，图中呈现了每个分类的均值点以及分界线。<br><img src="/2018/02/26/advanced-classification/svm1.jpg" title="线性均值分类器对坐标点的错误分类"><br>我们注意到，有一个坐标点被划分到错误的分类，而且它距离均值点计算得到分界线太近了。此处我们可以看出，因为大部分数据都是远离分界线的，所以判断数据是哪个分类与分类中心的距离关系较大，而与处于分界线的哪一侧关系较小。<br>支持向量机是一组方法的统称，它帮我们构造出解决上述问题的分类器。其思路是，尝试寻找尽可能远离所有分类中心的直线，这条线叫做”最大间隔超平面。如下图所示：<br><img src="/2018/02/26/advanced-classification/svm2.jpg" title="寻找两条最佳分界线"><br>此处选择分界线的依据是：寻找两条分别经过各分类相应坐标点的平行线，并使这两条平行线尽可能的远离分界线。此处，我可以根据两个分界线来判断一个新坐标点的所属分类。<br>只有位于间隔区边缘的坐标点才是确定两条分界线所必须的；我们可以去掉其余所有的数据，而两条分界线还会处于同样的位置，我们将确定这两条分界线处的坐标点叫做”支持向量”。寻找支持向量，并用支持向量来寻找两条分界线的算法便是<strong>支持向量机</strong>。<br>前面的论述中我们可以知道，只要利用点积的结果做比较，借助核技法就可以将一个线性分类器转换为非线性分类器。支持向量机使用的也是点积的结果，因此可以利用核技法将其应用于非线性分类。<br>SVM 只是用于2分类，如果扩展到多分类是需要训练技巧的，这方面的资料可自行查阅。</p><h1 id="使用libsvm"><a href="#使用libsvm" class="headerlink" title="使用libsvm"></a>使用libsvm</h1><p>前面的论述会使大家理解支持向量机的工作方式和工作原理，但是训练支持向量机所涉及的数学概念的计算量是非常庞大的，故实际使用的时候，我们会使用一个叫做libsvm的开源库，它能够对一个SVM模型进行训练、给出预测。</p><h1 id="联系"><a href="#联系" class="headerlink" title="联系"></a>联系</h1><ol><li>贝叶斯分类器 此处是否可以使用贝叶斯分类器？能够找到一个恰当的例子加以说明</li><li>我们是否可以利用前面所说的优化方法，而不是求均值的方式来确定分界线呢？ 你会选用怎样的成本函数？</li><li>选择最大的核参数 我们遍历不同的gamma参数，寻找最佳的ganmma值</li><li>兴趣爱好的层级排列 请为兴趣爱好设计一个简单的层级排列，并选用一个数据结构来描述它</li><li>试用不同的LIBSVM核方法 阅读SVM的文档，看看有哪些核方法可以使用，尝试使用多项式核方法(polynomial kernel)，看看预测效果是否有改进。</li></ol></div><div><div style="padding:10px 0;margin:20px auto;width:90%;text-align:center"><div>如果您觉得读完本文有收获，不妨小额赞助我一下，让我有动力继续写出高质量的教程！</div><button id="rewardButton" disable="enable"><span>打赏</span></button><div id="QR" style="display:block"><div id="wechat" style="display:inline-block"><img id="wechat_qr" src="/images/smacker.jpg" alt="倔强的土豆 微信支付"><p>微信支付</p></div></div></div></div><footer class="post-footer"><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/02/23/buildingPriceModels/" rel="next" title="构建价格模型"><i class="fa fa-chevron-left"></i> 构建价格模型</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></div></article><div class="post-spread"></div></div></div><div class="comments" id="comments"><div id="gitment-container"></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div id="sidebar-dimmer"></div><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">倔强的土豆</p><p class="site-description motion-element" itemprop="description">分享机器学习、深度学习的点滴</p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">10</span> <span class="site-state-item-name">日志</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/laiqun" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:laiqun@msn.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#数据集介绍"><span class="nav-number">1.</span> <span class="nav-text">数据集介绍</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#可视化数据集"><span class="nav-number">2.</span> <span class="nav-text">可视化数据集</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#使用决策树分类器做数据划分"><span class="nav-number">3.</span> <span class="nav-text">使用决策树分类器做数据划分</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#使用基本的线性分类对数据进行划分"><span class="nav-number">4.</span> <span class="nav-text">使用基本的线性分类对数据进行划分</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#将数据都转化为数值类型"><span class="nav-number">5.</span> <span class="nav-text">将数据都转化为数值类型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#将是-否问题转换为数值"><span class="nav-number">5.1.</span> <span class="nav-text">将是/否问题转换为数值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#将一对恋人的兴趣列表转换为数值"><span class="nav-number">5.2.</span> <span class="nav-text">将一对恋人的兴趣列表转换为数值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#将经纬度坐标转换为欧几里得距离"><span class="nav-number">5.3.</span> <span class="nav-text">将经纬度坐标转换为欧几里得距离</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#根据经纬度计算距离"><span class="nav-number">5.3.1.</span> <span class="nav-text">根据经纬度计算距离</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#将旧数据都转换为数值型的新数据"><span class="nav-number">5.4.</span> <span class="nav-text">将旧数据都转换为数值型的新数据</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对数据进行缩放-归一化"><span class="nav-number">6.</span> <span class="nav-text">对数据进行缩放(归一化)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#理解核方法"><span class="nav-number">7.</span> <span class="nav-text">理解核方法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#核技法"><span class="nav-number">7.1.</span> <span class="nav-text">核技法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#支持向量机"><span class="nav-number">8.</span> <span class="nav-text">支持向量机</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#使用libsvm"><span class="nav-number">9.</span> <span class="nav-text">使用libsvm</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#联系"><span class="nav-number">10.</span> <span class="nav-text">联系</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2018</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">倔强的土豆</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.3</div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script><link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css"><script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script><script type="text/javascript">function renderGitment(){var a=new Gitmint({id:window.location.pathname,owner:"laiqun",repo:"laiqun.github.io",lang:navigator.language||navigator.systemLanguage||navigator.userLanguage,oauth:{client_secret:"55aaeb736714431ea52109dd66461b1644ca6177",client_id:"c90dfa80285ea91b9120"}});a.render("gitment-container")}renderGitment()</script></body></html><!-- rebuild by neat -->